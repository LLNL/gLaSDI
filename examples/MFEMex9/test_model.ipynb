{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from autoencoder import full_network\n",
    "from training import create_feed_dictionary, create_feed_dictionary2, eval_model, max_err_heatmap\n",
    "from sindy_utils import *\n",
    "from error_utils import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "import subprocess as sp\n",
    "%matplotlib inline\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import copy\n",
    "\n",
    "def get_cmap(n, name='tab20'):\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "cmap = get_cmap(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory():\n",
    "  _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "  memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "  memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "  return memory_free_values\n",
    "\n",
    "device_list = tf.config.list_physical_devices('GPU')\n",
    "free_mem = get_gpu_memory()\n",
    "for i,gpu in enumerate(device_list):\n",
    "    print(f'{gpu}: free memory: {free_mem[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which GPU to use\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=tf.GPUOptions(allow_growth=True,\n",
    "                                                                              visible_device_list='1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Trained gLaSDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '/fig/nCase121_tstop3_ld3_p1_1e-2_lr1e-3_width100_nDI25_upEP2e4_resNS0.1/'\n",
    "save_name = 'ex9_2022_02_06_08_44_55'\n",
    "params = pickle.load(open(data_path + save_name + '_params.pkl', 'rb'))\n",
    "params['save_name'] = data_path + save_name\n",
    "params['config'] = config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation by One Parameter Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = 1\n",
    "w1 = 1.5\n",
    "w2 = 2\n",
    "tstop = 3\n",
    "t_test = tstop\n",
    "test_data = pickle.load(open(f\"/g/g92/he10/Research/data/MFEMex9/local1_p1{w1:.1f}_p2{w2:.1f}_tstop{tstop:.1f}.p\", \"rb\"))\n",
    "nt = test_data['data'][0]['x'].shape[0]\n",
    "t = np.linspace(0,t_test,nt)\n",
    "\n",
    "# discretization coordinates\n",
    "vert = np.loadtxt('/g/g92/he10/Research/data/MFEMex9/vertex.txt')\n",
    "triang = tri.Triangulation(vert[:,0], vert[:,1])\n",
    "\n",
    "test_data_x = test_data['data'][0]['x']\n",
    "test_data_dx = test_data['data'][0]['dx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_decoder,du_decoder,u_sim,du_sim,z_encoder,dz_encoder,z_sim,dz_sim,idx,timer_rom = eval_model(test_data['data'][0], params,\n",
    "                                                                                               test_data['param'][0], knn=knn,\n",
    "                                                                                               calc_dz=True, calc_du=True)\n",
    "u_decoder = u_decoder.squeeze()\n",
    "print(z_sim.shape, u_sim.shape, u_decoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max relative error\n",
    "err_decoder = np.linalg.norm(test_data_x - u_decoder, axis=1) / np.linalg.norm(test_data_x, axis=1)*100\n",
    "err_sindy = np.linalg.norm(test_data_x - u_sim, axis=1) / np.linalg.norm(test_data_x, axis=1)*100\n",
    "print(f'max autoencoder error: {err_decoder.max():.2f} %')\n",
    "print(f'max sindy-decoder error: {err_sindy.max():.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstep = 8\n",
    "step_list = np.linspace(0,nt-1,nstep).astype(int)\n",
    "vmin_x = test_data_x.min()\n",
    "vmax_x = test_data_x.max()\n",
    "vmin_dx = test_data_dx.min()/10\n",
    "vmax_dx = test_data_dx.max()/10\n",
    "\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "for i,step in enumerate(step_list):\n",
    "    ax = fig.add_subplot(4,nstep,i+1)\n",
    "    ax.tripcolor(triang, test_data_x[step], shading='gouraud', vmin=vmin_x, vmax=vmax_x)\n",
    "    ax.set_title(f'u - step: {step}', fontsize=16)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "for i,step in enumerate(step_list):\n",
    "    ax = fig.add_subplot(4,nstep,i+1+nstep)\n",
    "    ax.tripcolor(triang, u_sim[step], shading='gouraud', vmin=vmin_x, vmax=vmax_x)\n",
    "    ax.set_title(r'$u_{pred}$' + f' - step: {step}', fontsize=16)\n",
    "    ax.set_aspect('equal')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(data_path + f\"inter_pred_multisteps.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 24,\n",
    "                     \"font.family\": \"sans-serif\"}) # fontsize for figures\n",
    "\n",
    "fig1 = plt.figure(figsize=(12,5))\n",
    "line_type = ['-','-*','-.','-^','-s']\n",
    "idx = np.arange(0,t.size,10)\n",
    "ax = fig1.add_subplot(121)\n",
    "for i in range(z_encoder.shape[1]):\n",
    "    ax.plot(t, z_encoder[:,i], '-', lw=2, c=cmap(i))\n",
    "    ax.plot(t[idx], z_sim[idx,i], '--o', lw=2, markersize=5, c=cmap(i))\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('z')\n",
    "ax.set_xticks(np.linspace(0,t.max(),5))\n",
    "ax.set_ylim(z_sim.min()*1.1,z_sim.max()+1.2)\n",
    "ax.tick_params(axis='both', labelsize=24)\n",
    "ax.legend(['Encoder', 'DI'], loc='upper right', frameon=False, fontsize=24)\n",
    "ax.set_xlim(t.min(),t.max())\n",
    "\n",
    "ax = fig1.add_subplot(122)\n",
    "for i in range(z_sim.shape[1]):\n",
    "    ax.plot(t, dz_encoder[:,i], '-', linewidth=2, c=cmap(i))\n",
    "    ax.plot(t[idx], dz_sim[idx,i], '--o', linewidth=2, markersize=5, c=cmap(i))\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('dz/dt')\n",
    "ax.set_xticks(np.linspace(0,t.max(),5))\n",
    "ax.set_xlim(0,t.max())\n",
    "ax.set_ylim(dz_sim.min()*1.1,dz_sim.max()*1.3)\n",
    "ax.tick_params(axis='both', labelsize=24)\n",
    "ax.legend(['Encoder', 'DI'], loc='upper right', frameon=False, fontsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(data_path + f\"advection_latent_dynamics.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation by the Prescribed Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = 4\n",
    "res_name = f'mean'\n",
    "\n",
    "na = 21\n",
    "nw = na\n",
    "p1_test = np.linspace(1.5, 2, na)\n",
    "p2_test = np.linspace(2, 2.5, nw)\n",
    "num_case = p1_test.size * p2_test.size\n",
    "max_err = np.zeros([len(p1_test), len(p2_test)])\n",
    "res_norm = np.zeros([len(p1_test), len(p2_test)])\n",
    "sindy_idx = np.zeros([len(p1_test), len(p2_test)])\n",
    "test_data_all = pickle.load(open(f\"/g/g92/he10/Research/data/MFEMex9/local{num_case}_tstop{tstop:.1f}.p\", \"rb\"))\n",
    "\n",
    "speed_up = 0\n",
    "count = 0\n",
    "timer_rom = np.zeros(4)\n",
    "start_time = time()\n",
    "for i,a in enumerate(p1_test):\n",
    "    for j,w in enumerate(p2_test):\n",
    "        print(f\"{count}/{num_case}: {test_data_all['param'][count]}\")\n",
    "        test_data = {}\n",
    "        test_data['data'] = [deepcopy(test_data_all['data'][count])]\n",
    "        test_data['param'] = [deepcopy(test_data_all['param'][count])]\n",
    "        \n",
    "        _,_,u_sim,_,_,_,_,_,idx,t_rom = eval_model(test_data['data'][0], params, \n",
    "                                                   test_data['param'][0], knn=knn)\n",
    "        timer_rom += t_rom\n",
    "        sindy_idx[i,j] = idx+1\n",
    "        \n",
    "        # Max error of all time steps\n",
    "        max_err[i,j] = (np.linalg.norm(test_data['data'][0]['x'] - u_sim, axis=1) \\\n",
    "                        / np.linalg.norm(test_data['data'][0]['x'], axis=1)*100).max()\n",
    "        \n",
    "        # residual norm\n",
    "        res_norm[i,j] = err_indicator(u_sim, params, err_type=params['err_type'])\n",
    "        count += 1\n",
    "\n",
    "end_time = time()\n",
    "time_rom = timer_rom[1:].sum()/num_case # from Step 2 to 4\n",
    "time_sim = 3.8 # seconds\n",
    "speed_up = time_sim / time_rom\n",
    "print(f'Time taken: {end_time-start_time:.2f} s, {(end_time-start_time)/60:.2f} mins')\n",
    "print(f'Max relative error: {max_err.max() :.2f} %')\n",
    "print(f'Average speed up: {speed_up:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_grid, w_grid = np.meshgrid(p1_test, p2_test)\n",
    "param_list = np.hstack([a_grid.flatten().reshape(-1,1), w_grid.flatten().reshape(-1,1)])\n",
    "a_grid, w_grid = np.meshgrid(np.arange(p1_test.size), np.arange(p2_test.size))\n",
    "idx_list = np.hstack([a_grid.flatten().reshape(-1,1), w_grid.flatten().reshape(-1,1)])\n",
    "\n",
    "idx_param = []\n",
    "for i,ip in enumerate(params['param']):\n",
    "    idx = np.argmin(np.linalg.norm(param_list-ip, axis=1))\n",
    "    idx_param.append((idx, np.array([param_list[idx,0], param_list[idx,1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_err_heatmap(max_err, sindy_idx, params, p1_test, p2_test, data_path, idx_list, idx_param,\n",
    "                xlabel='w2', ylabel='w1', dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the residual-based errors are scaled by the \"scale\" parameter\n",
    "max_err_heatmap(res_norm, sindy_idx, params, p1_test, p2_test, data_path, idx_list, idx_param,\n",
    "                xlabel='w2', ylabel='w1', label='Residual Norm', dtype='float', scale=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "tfvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
