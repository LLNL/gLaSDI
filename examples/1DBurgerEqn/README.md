The gLaSDI framework is applied to construct a non-intrusive reduced-order model of the **1D Burgers' Equation**.


The data can be generated by `generate_data.ipynb`. Alternatively, some datasets are avaiable in `/usr/workspace/he10/data/1DBurgerEqn/`, which are used in the numerical examples in the paper. The datasets are generated from the parameter space constituted by the parameters of the initial condition, including the **width** ([0.9,1.1]) and the **amplitude** ([0.7,0.9]).
- `local4.p`: 2x2 parameter cases on the given parameter space; initial parameter cases located at the corners of the parameter space
- `local441.p`: 21x21 parameter cases on the given parameter space; a dataset of discrete parameter space for adaptive greedy sampling and evaluation


Note that to enhance the training efficiency, the dataset of a discrete parameter space (e.g., 21x21 parameter cases) for adaptive greedy sampling is generated before training starts, which means the solution of the optimal parameter case (with the maximum error indicator) is retrieved from the dataset without calling the solver of the full-order model during training. The proposed gLaSDI framework can be adapted to a continuous parameter space and the solution of sampled parameter cases can be generated by running full-order model simulations during training.


Procedure:
- run `generate_data.ipynb` to generate dataset
- run `train_model.ipynb` to train a gLaSDI model by submitting a job using `batch_job.bsub`
- run `test_model.ipynb` to evalute the trained model
- run `plot_heatmap.ipynb` to plot the greedy sampling process in terms of the error indicator


If the training time exceeds the maximum allowable wall time, the training can be continued by updating the following parameters in `train_model.ipynb` and submitting additoinal jobs:
- `params['retrain'] = True`
- `save_name` (file name of the trained model)