{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /g/g92/he10/.conda/envs/tfvenv/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from solver_1DBurger import get_data_1DBurger\n",
    "import numpy as np\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle \n",
    "import copy\n",
    "import subprocess as sp\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): free memory: 7612\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'): free memory: 13799\n",
      "PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'): free memory: 16149\n",
      "PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'): free memory: 16149\n"
     ]
    }
   ],
   "source": [
    "def get_gpu_memory():\n",
    "  _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n",
    "\n",
    "  ACCEPTABLE_AVAILABLE_MEMORY = 1024\n",
    "  COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "  memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n",
    "  memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "  return memory_free_values\n",
    "\n",
    "device_list = tf.config.list_physical_devices('GPU')\n",
    "free_mem = get_gpu_memory()\n",
    "for i,gpu in enumerate(device_list):\n",
    "    print(f'{gpu}: free memory: {free_mem[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which GPU to use\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 0: params: [0.7 0.9], x shape: (1001, 1001)\n",
      "case 1: params: [0.7 1.1], x shape: (1001, 1001)\n",
      "case 2: params: [0.9 0.9], x shape: (1001, 1001)\n",
      "case 3: params: [0.9 1.1], x shape: (1001, 1001)\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "amp_train = np.linspace(0.7,0.9,2)\n",
    "width_train = np.linspace(0.9,1.1,2)\n",
    "num_train = 4  # number of training cases\n",
    "nx = 1001\n",
    "nt = 1000\n",
    "tstop = 1.0\n",
    "scaled = False # if data is normalized\n",
    "train_data = pickle.load(open(f\"./data/local{num_train}.p\", \"rb\"))  # local4.p is for A:[0.7,0.9], W:[0.9,1.1]\n",
    "# train_data = pickle.load(open(f\"./data/local{num_train}b.p\", \"rb\")) # local4b.p is for A:[0.6,1.0], W:[0.8,1.2]\n",
    "num_sindy = len(train_data['data'])\n",
    "input_dim = train_data['data'][0]['x'].shape[1]\n",
    "\n",
    "# testing data\n",
    "# amp_test = np.arange(0.7,0.9,0.05)\n",
    "# width_test = np.arange(0.9,1.1,0.05)\n",
    "amp_test = np.linspace(0.7,0.9,21)\n",
    "width_test = np.linspace(0.9,1.1,21)\n",
    "num_test = amp_test.size * width_test.size\n",
    "test_data = pickle.load(open(f\"./data/local{num_test}.p\", \"rb\"))\n",
    "\n",
    "for i in range(num_sindy):\n",
    "    print(f\"case {i}: params: {train_data['param'][i]}, x shape: {train_data['data'][i]['x'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 20, 420, 440]\n"
     ]
    }
   ],
   "source": [
    "grid1, grid2 = np.meshgrid(amp_train, width_train)\n",
    "train_param = np.hstack((grid1.flatten().reshape(-1,1), grid2.flatten().reshape(-1,1)))\n",
    "grid1, grid2 = np.meshgrid(amp_test, width_test)\n",
    "test_param = np.hstack((grid1.flatten().reshape(-1,1), grid2.flatten().reshape(-1,1)))\n",
    "\n",
    "train_idx = []\n",
    "for i in range(num_test):\n",
    "    for j in range(num_train):\n",
    "        if np.abs(test_param[i,0]-train_param[j,0]) < 1e-8 and \\\n",
    "        np.abs(test_param[i,1]-train_param[j,1]) < 1e-8:\n",
    "            train_idx.append(i)\n",
    "print(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'param'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data.keys())\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(np.linspace(-3,3,nx),train_data['data'][0]['x'][-1,:])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('u')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(np.linspace(-3,3,nx),train_data['data'][0]['dx'][-1,:])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('du/dt')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['seed'] = 1 # random seed\n",
    "params['config'] = config\n",
    "params['num_sindy'] = num_sindy\n",
    "params['param'] = train_data['param']\n",
    "params['train_idx'] = train_idx\n",
    "params['input_dim'] = input_dim\n",
    "params['latent_dim'] = 5\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 1\n",
    "params['include_sine'] = False\n",
    "params['include_cosine'] = False\n",
    "params['include_costant'] = True\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], \n",
    "                                     params['include_sine'], params['include_cosine'], \n",
    "                                     params['include_costant'])\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = False\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_x'] = 1e-1\n",
    "params['loss_weight_sindy_z'] = 1e-1\n",
    "params['loss_weight_sindy_regularization'] = 0\n",
    "params['diff'] = 'symb' # 'symb': symbolic diff (only for fully connected Autoencoder), 'auto': automatic diff\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [100]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = train_data['data'][0]['x'].shape[0]\n",
    "params['batch_size'] = 100\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['fig_path'] = os.getcwd() + '/fig/nCase441_k1_MRN_ld5_subsize50_upfreq2000/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "params['save_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 120000  # max number of training epochs\n",
    "params['refinement_epochs'] = 0\n",
    "\n",
    "# Greedy algorithm\n",
    "params['update_epoch'] = 2000 # update training set for every 2000 epochs\n",
    "params['tol'] = 0.001         # max error allowed in the parameter space\n",
    "params['tol2'] = 2            # max relative error allowed in the parameter space\n",
    "params['sindy_max'] = 25      # max number of local SINDys; if tolerance is used as a termination criterior, set it as None\n",
    "params['convex_knn'] = 1      # the number nearest local SINDys used for convex interpolation during Greedy sampling\n",
    "params['test_data'] = test_data # path of test data\n",
    "params['test_param'] = np.hstack((amp_test.reshape(-1,1), width_test.reshape(-1,1)))    # parameters of test data\n",
    "params['num_test'] = num_test                     # number of test cases\n",
    "params['coeff_exist'] = False                     # flag to indicate whether to initialize model coefficients with pescribed values\n",
    "params['retrain'] = False     # whether to retrain the model\n",
    "\n",
    "# Error indicator:\n",
    "# 1: max relative error (if test data is available) \n",
    "# 2: residual norm (mean), 1D Burger's eqn\n",
    "# 3: residual norm (mean), 2D Burger's eqn\n",
    "params['err_type'] = 2                            \n",
    "params['subsize'] = int(0.5 * num_test)           # initial number of random testing cases for Greedy search\n",
    "params['subsize_max'] = 60                        # max percentage of random testing cases for Greedy search\n",
    "\n",
    "# Adaptive approach for tol of error indicator:\n",
    "# 'mean': use mean ratios between error indicator and max relative errors\n",
    "# 'reg_mean': use linear regression line\n",
    "# 'reg_max': use linear regression line shifted by std to upper bound\n",
    "# 'reg_min': use linear regression line shifted by std to lower bound, more conservative\n",
    "params['adaptive'] = 'reg_max'                      \n",
    "\n",
    "# PDE parameters\n",
    "params['pde'] = {}\n",
    "params['pde']['nx'] = nx\n",
    "params['pde']['nt'] = nt\n",
    "params['pde']['tstop'] = tstop\n",
    "\n",
    "# normalization\n",
    "params['scaled'] = scaled # if data is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['retrain']:\n",
    "    save_name = 'burger_2021_11_26_10_02_50'\n",
    "    params = pickle.load(open(params['fig_path'] + save_name + '_params.pkl', 'rb'))\n",
    "    params['retrain'] = True\n",
    "    params['coeff_exist'] = True  # flag to indicate whether to initialize model coefficients with pescribed values\n",
    "    params['save_name'] = save_name\n",
    "    params['max_epochs'] = 5000\n",
    "    params['update_epoch'] = 5000  # update training set for every 2000 epochs\n",
    "    params['save_frequency'] = 1000\n",
    "    \n",
    "    for i in params['train_idx'][4:]:\n",
    "        train_data['data'].append(test_data['data'][i])\n",
    "        train_data['param'].append(test_data['param'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "* Evaluating\n",
      "  Time: 15.11 s, Case: [0.72 0.9 ], Tol: 0.00100, Max Error: 0.510305\n",
      "Epoch 0\n",
      "  train loss: 3.4599e-01, decoder: 1.4247e-01, sindy-x: 1.1721e-01, sindy-z: 1.9180e+00, sindy-reg: 3.9924\n",
      "Epoch 100\n",
      "  train loss: 3.2830e-02, decoder: 2.1196e-02, sindy-x: 1.1393e-01, sindy-z: 2.4097e-03, sindy-reg: 3.8647\n",
      "Epoch 200\n",
      "  train loss: 1.3220e-02, decoder: 6.8418e-03, sindy-x: 4.3519e-02, sindy-z: 2.0267e-02, sindy-reg: 3.8058\n",
      "Epoch 300\n",
      "  train loss: 7.2778e-03, decoder: 2.1189e-03, sindy-x: 3.3307e-02, sindy-z: 1.8282e-02, sindy-reg: 3.7797\n",
      "Epoch 400\n",
      "  train loss: 2.6099e-03, decoder: 7.9296e-04, sindy-x: 1.6432e-02, sindy-z: 1.7377e-03, sindy-reg: 3.7633\n",
      "Epoch 500\n",
      "  train loss: 3.2139e-03, decoder: 1.5447e-03, sindy-x: 1.0448e-02, sindy-z: 6.2434e-03, sindy-reg: 3.7373\n",
      "Epoch 600\n",
      "  train loss: 1.2230e-03, decoder: 1.9426e-04, sindy-x: 8.2777e-03, sindy-z: 2.0098e-03, sindy-reg: 3.7168\n",
      "Epoch 700\n",
      "  train loss: 1.2833e-03, decoder: 2.6063e-04, sindy-x: 7.5400e-03, sindy-z: 2.6868e-03, sindy-reg: 3.6837\n",
      "Epoch 800\n",
      "  train loss: 4.0080e-03, decoder: 1.2339e-03, sindy-x: 8.2012e-03, sindy-z: 1.9540e-02, sindy-reg: 3.6592\n",
      "Epoch 900\n",
      "  train loss: 3.0249e-03, decoder: 5.1488e-04, sindy-x: 7.6690e-03, sindy-z: 1.7432e-02, sindy-reg: 3.6293\n",
      "Epoch 1000\n",
      "  train loss: 8.1414e-04, decoder: 4.0766e-05, sindy-x: 5.2886e-03, sindy-z: 2.4451e-03, sindy-reg: 3.6069\n",
      "Epoch 1100\n",
      "  train loss: 5.2920e-03, decoder: 9.6733e-04, sindy-x: 7.5853e-03, sindy-z: 3.5662e-02, sindy-reg: 3.5750\n",
      "Epoch 1200\n",
      "  train loss: 2.8265e-03, decoder: 1.9931e-03, sindy-x: 4.4384e-03, sindy-z: 3.8952e-03, sindy-reg: 3.5492\n",
      "Epoch 1300\n",
      "  train loss: 3.7764e-04, decoder: 3.9889e-05, sindy-x: 2.5391e-03, sindy-z: 8.3836e-04, sindy-reg: 3.5290\n",
      "Epoch 1400\n",
      "  train loss: 6.9498e-04, decoder: 2.3934e-04, sindy-x: 2.6607e-03, sindy-z: 1.8957e-03, sindy-reg: 3.5050\n",
      "Epoch 1500\n",
      "  train loss: 8.9408e-04, decoder: 3.3226e-05, sindy-x: 3.9096e-03, sindy-z: 4.6990e-03, sindy-reg: 3.4889\n",
      "Epoch 1600\n",
      "  train loss: 4.7224e-04, decoder: 4.8562e-05, sindy-x: 2.3668e-03, sindy-z: 1.8700e-03, sindy-reg: 3.4665\n",
      "Epoch 1700\n",
      "  train loss: 4.3185e-04, decoder: 8.4935e-05, sindy-x: 2.2328e-03, sindy-z: 1.2363e-03, sindy-reg: 3.4430\n",
      "Epoch 1800\n",
      "  train loss: 3.1058e-04, decoder: 1.9083e-05, sindy-x: 1.9947e-03, sindy-z: 9.2026e-04, sindy-reg: 3.4160\n",
      "Epoch 1900\n",
      "  train loss: 3.5592e-04, decoder: 8.5589e-05, sindy-x: 2.1454e-03, sindy-z: 5.5790e-04, sindy-reg: 3.3882\n",
      "* Evaluating\n",
      "  Time: 14.13 s, Case: [0.77 1.  ], Tol: 0.00100, Max Error: 0.070770\n",
      "  Update tolerance for error indicator from 0.00100 to 0.00103\n",
      "* Update Training set: add case [0.77 1.  ]\n",
      "* Updating graph\n",
      "  Existing SINDys: 4, Create new SINDy: 5\n",
      "Epoch 2000\n",
      "  train loss: 1.1806e-02, decoder: 4.8807e-03, sindy-x: 8.8148e-03, sindy-z: 6.0435e-02, sindy-reg: 4.1667\n",
      "Epoch 2100\n",
      "  train loss: 4.5018e-04, decoder: 1.4485e-04, sindy-x: 2.1567e-03, sindy-z: 8.9649e-04, sindy-reg: 4.1258\n",
      "Epoch 2200\n",
      "  train loss: 6.2898e-04, decoder: 1.5647e-04, sindy-x: 2.1601e-03, sindy-z: 2.5650e-03, sindy-reg: 4.1081\n",
      "Epoch 2300\n",
      "  train loss: 1.9292e-03, decoder: 1.5837e-04, sindy-x: 4.5117e-03, sindy-z: 1.3196e-02, sindy-reg: 4.0706\n",
      "Epoch 2400\n",
      "  train loss: 3.8789e-04, decoder: 6.5953e-05, sindy-x: 1.5517e-03, sindy-z: 1.6676e-03, sindy-reg: 4.0290\n",
      "Epoch 2500\n",
      "  train loss: 3.4856e-04, decoder: 7.4312e-05, sindy-x: 1.4777e-03, sindy-z: 1.2649e-03, sindy-reg: 3.9925\n",
      "Epoch 2600\n",
      "  train loss: 2.0777e-04, decoder: 3.2435e-05, sindy-x: 1.2922e-03, sindy-z: 4.6121e-04, sindy-reg: 3.9551\n",
      "Epoch 2700\n",
      "  train loss: 9.8016e-04, decoder: 4.0699e-04, sindy-x: 2.2229e-03, sindy-z: 3.5088e-03, sindy-reg: 3.9062\n",
      "Epoch 2800\n",
      "  train loss: 1.1075e-03, decoder: 5.5965e-05, sindy-x: 1.9614e-03, sindy-z: 8.5543e-03, sindy-reg: 3.8615\n",
      "Epoch 2900\n",
      "  train loss: 6.0008e-04, decoder: 3.3893e-04, sindy-x: 1.3088e-03, sindy-z: 1.3027e-03, sindy-reg: 3.8201\n",
      "Epoch 3000\n",
      "  train loss: 1.8437e-04, decoder: 1.3631e-05, sindy-x: 9.3563e-04, sindy-z: 7.7178e-04, sindy-reg: 3.7923\n",
      "Epoch 3100\n",
      "  train loss: 1.3920e-04, decoder: 2.5890e-05, sindy-x: 8.6712e-04, sindy-z: 2.6596e-04, sindy-reg: 3.7592\n",
      "Epoch 3200\n",
      "  train loss: 3.9253e-04, decoder: 2.0945e-04, sindy-x: 8.9244e-04, sindy-z: 9.3833e-04, sindy-reg: 3.7338\n",
      "Epoch 3300\n",
      "  train loss: 1.4990e-04, decoder: 1.6993e-05, sindy-x: 8.7102e-04, sindy-z: 4.5802e-04, sindy-reg: 3.7175\n",
      "Epoch 3400\n",
      "  train loss: 9.1348e-04, decoder: 5.5360e-05, sindy-x: 1.9303e-03, sindy-z: 6.6509e-03, sindy-reg: 3.6931\n",
      "Epoch 3500\n",
      "  train loss: 1.1727e-03, decoder: 6.8518e-05, sindy-x: 2.1008e-03, sindy-z: 8.9411e-03, sindy-reg: 3.6723\n",
      "Epoch 3600\n",
      "  train loss: 1.6787e-04, decoder: 1.2495e-05, sindy-x: 7.4748e-04, sindy-z: 8.0625e-04, sindy-reg: 3.6514\n",
      "Epoch 3700\n",
      "  train loss: 6.1141e-04, decoder: 1.1166e-04, sindy-x: 1.0898e-03, sindy-z: 3.9078e-03, sindy-reg: 3.6293\n",
      "Epoch 3800\n",
      "  train loss: 5.6893e-04, decoder: 3.4466e-05, sindy-x: 9.1426e-04, sindy-z: 4.4304e-03, sindy-reg: 3.6086\n",
      "Epoch 3900\n",
      "  train loss: 2.2306e-04, decoder: 2.8262e-05, sindy-x: 7.2001e-04, sindy-z: 1.2280e-03, sindy-reg: 3.5860\n",
      "* Evaluating\n",
      "  Time: 16.63 s, Case: [0.9 1. ], Tol: 0.00103, Max Error: 0.059128\n",
      "  Update tolerance for error indicator from 0.00103 to 0.00081\n",
      "* Update Training set: add case [0.9 1. ]\n",
      "* Updating graph\n",
      "  Existing SINDys: 5, Create new SINDy: 6\n",
      "Epoch 4000\n",
      "  train loss: 6.4908e-03, decoder: 2.2623e-03, sindy-x: 6.3745e-03, sindy-z: 3.5910e-02, sindy-reg: 4.2691\n",
      "Epoch 4100\n",
      "  train loss: 4.5392e-04, decoder: 2.0875e-04, sindy-x: 9.7683e-04, sindy-z: 1.4749e-03, sindy-reg: 4.2461\n",
      "Epoch 4200\n",
      "  train loss: 1.2703e-03, decoder: 7.2028e-04, sindy-x: 1.2982e-03, sindy-z: 4.2020e-03, sindy-reg: 4.2138\n",
      "Epoch 4300\n",
      "  train loss: 3.8289e-04, decoder: 7.6837e-05, sindy-x: 9.3223e-04, sindy-z: 2.1283e-03, sindy-reg: 4.1879\n",
      "Epoch 4400\n",
      "  train loss: 7.9542e-04, decoder: 1.0063e-04, sindy-x: 1.5310e-03, sindy-z: 5.4168e-03, sindy-reg: 4.1649\n",
      "Epoch 4500\n",
      "  train loss: 1.7894e-04, decoder: 6.8598e-05, sindy-x: 6.3285e-04, sindy-z: 4.7060e-04, sindy-reg: 4.1402\n",
      "Epoch 4600\n",
      "  train loss: 3.3028e-04, decoder: 1.3460e-04, sindy-x: 8.1426e-04, sindy-z: 1.1425e-03, sindy-reg: 4.1109\n",
      "Epoch 4700\n",
      "  train loss: 3.6117e-04, decoder: 7.9807e-05, sindy-x: 8.0369e-04, sindy-z: 2.0100e-03, sindy-reg: 4.0918\n",
      "Epoch 4800\n",
      "  train loss: 1.5172e-04, decoder: 4.8212e-05, sindy-x: 6.3665e-04, sindy-z: 3.9843e-04, sindy-reg: 4.0686\n",
      "Epoch 4900\n",
      "  train loss: 2.6746e-04, decoder: 5.6324e-05, sindy-x: 7.3773e-04, sindy-z: 1.3736e-03, sindy-reg: 4.0496\n",
      "Epoch 5000\n",
      "  train loss: 2.0205e-04, decoder: 4.7578e-05, sindy-x: 6.8787e-04, sindy-z: 8.5684e-04, sindy-reg: 4.0338\n",
      "Epoch 5100\n",
      "  train loss: 2.4773e-04, decoder: 6.2926e-05, sindy-x: 8.7479e-04, sindy-z: 9.7324e-04, sindy-reg: 4.0097\n",
      "Epoch 5200\n",
      "  train loss: 1.8307e-04, decoder: 3.8192e-05, sindy-x: 8.2259e-04, sindy-z: 6.2622e-04, sindy-reg: 3.9923\n",
      "Epoch 5300\n",
      "  train loss: 1.2494e-04, decoder: 2.6932e-05, sindy-x: 6.1897e-04, sindy-z: 3.6113e-04, sindy-reg: 3.9648\n",
      "Epoch 5400\n",
      "  train loss: 1.5874e-04, decoder: 3.3884e-05, sindy-x: 6.9389e-04, sindy-z: 5.5468e-04, sindy-reg: 3.9494\n",
      "Epoch 5500\n",
      "  train loss: 3.0804e-04, decoder: 7.7835e-05, sindy-x: 1.2149e-03, sindy-z: 1.0871e-03, sindy-reg: 3.9186\n",
      "Epoch 5600\n",
      "  train loss: 3.2603e-04, decoder: 1.2746e-04, sindy-x: 8.4212e-04, sindy-z: 1.1436e-03, sindy-reg: 3.8931\n",
      "Epoch 5700\n",
      "  train loss: 5.1579e-04, decoder: 1.3439e-04, sindy-x: 1.0060e-03, sindy-z: 2.8080e-03, sindy-reg: 3.8683\n",
      "Epoch 5800\n",
      "  train loss: 1.2515e-04, decoder: 1.6320e-05, sindy-x: 6.9984e-04, sindy-z: 3.8843e-04, sindy-reg: 3.8455\n",
      "Epoch 5900\n",
      "  train loss: 2.4349e-04, decoder: 4.4393e-05, sindy-x: 6.5680e-04, sindy-z: 1.3342e-03, sindy-reg: 3.8335\n",
      "* Evaluating\n",
      "  Time: 17.39 s, Case: [0.8  1.09], Tol: 0.00081, Max Error: 0.011529\n",
      "  Update tolerance for error indicator from 0.00081 to 0.00062\n",
      "* Update Training set: add case [0.8  1.09]\n",
      "* Updating graph\n",
      "  Existing SINDys: 6, Create new SINDy: 7\n",
      "Epoch 6000\n",
      "  train loss: 8.7143e-03, decoder: 2.9063e-03, sindy-x: 6.8487e-03, sindy-z: 5.1231e-02, sindy-reg: 4.4190\n",
      "Epoch 6100\n",
      "  train loss: 1.3471e-03, decoder: 3.1763e-04, sindy-x: 2.1156e-03, sindy-z: 8.1791e-03, sindy-reg: 4.3941\n",
      "Epoch 6200\n",
      "  train loss: 3.3186e-04, decoder: 1.0085e-04, sindy-x: 1.3720e-03, sindy-z: 9.3807e-04, sindy-reg: 4.3882\n",
      "Epoch 6300\n",
      "  train loss: 6.0335e-04, decoder: 1.7268e-04, sindy-x: 8.6809e-04, sindy-z: 3.4386e-03, sindy-reg: 4.3694\n",
      "Epoch 6400\n",
      "  train loss: 3.3770e-04, decoder: 2.1750e-04, sindy-x: 7.1458e-04, sindy-z: 4.8741e-04, sindy-reg: 4.3568\n",
      "Epoch 6500\n",
      "  train loss: 2.6904e-04, decoder: 8.4094e-05, sindy-x: 7.3383e-04, sindy-z: 1.1156e-03, sindy-reg: 4.3424\n",
      "Epoch 6600\n",
      "  train loss: 1.6261e-04, decoder: 6.1717e-05, sindy-x: 6.3810e-04, sindy-z: 3.7083e-04, sindy-reg: 4.3290\n",
      "Epoch 6700\n",
      "  train loss: 2.7438e-04, decoder: 1.2501e-04, sindy-x: 8.7655e-04, sindy-z: 6.1720e-04, sindy-reg: 4.3150\n",
      "Epoch 6800\n",
      "  train loss: 1.5200e-04, decoder: 4.3554e-05, sindy-x: 6.5660e-04, sindy-z: 4.2783e-04, sindy-reg: 4.2996\n",
      "Epoch 6900\n",
      "  train loss: 3.6914e-04, decoder: 8.7833e-05, sindy-x: 1.2001e-03, sindy-z: 1.6130e-03, sindy-reg: 4.2899\n",
      "Epoch 7000\n",
      "  train loss: 2.6755e-04, decoder: 7.4840e-05, sindy-x: 9.1358e-04, sindy-z: 1.0135e-03, sindy-reg: 4.2742\n",
      "Epoch 7100\n",
      "  train loss: 9.2372e-04, decoder: 1.0592e-04, sindy-x: 1.5886e-03, sindy-z: 6.5895e-03, sindy-reg: 4.2644\n",
      "Epoch 7200\n",
      "  train loss: 3.9730e-04, decoder: 2.1765e-04, sindy-x: 1.2212e-03, sindy-z: 5.7520e-04, sindy-reg: 4.2518\n",
      "Epoch 7300\n",
      "  train loss: 1.6165e-03, decoder: 2.6113e-04, sindy-x: 2.5111e-03, sindy-z: 1.1043e-02, sindy-reg: 4.2398\n",
      "Epoch 7400\n",
      "  train loss: 1.7305e-04, decoder: 3.6538e-05, sindy-x: 6.3366e-04, sindy-z: 7.3151e-04, sindy-reg: 4.2091\n",
      "Epoch 7500\n",
      "  train loss: 4.7639e-04, decoder: 2.0691e-04, sindy-x: 6.1944e-04, sindy-z: 2.0753e-03, sindy-reg: 4.1914\n",
      "Epoch 7600\n",
      "  train loss: 2.1730e-04, decoder: 5.4912e-05, sindy-x: 8.1709e-04, sindy-z: 8.0678e-04, sindy-reg: 4.1698\n",
      "Epoch 7700\n",
      "  train loss: 2.0142e-04, decoder: 7.4012e-05, sindy-x: 8.2767e-04, sindy-z: 4.4644e-04, sindy-reg: 4.1415\n",
      "Epoch 7800\n",
      "  train loss: 1.2660e-04, decoder: 3.4269e-05, sindy-x: 6.4122e-04, sindy-z: 2.8210e-04, sindy-reg: 4.1278\n",
      "Epoch 7900\n",
      "  train loss: 2.6593e-04, decoder: 3.0035e-05, sindy-x: 8.4472e-04, sindy-z: 1.5142e-03, sindy-reg: 4.1146\n",
      "* Evaluating\n",
      "  Time: 15.11 s, Case: [0.79 0.91], Tol: 0.00062, Max Error: 0.005070\n",
      "  Update tolerance for error indicator from 0.00062 to 0.00051\n",
      "* Update Training set: add case [0.79 0.91]\n",
      "* Updating graph\n",
      "  Existing SINDys: 7, Create new SINDy: 8\n",
      "Epoch 8000\n",
      "  train loss: 5.3404e-03, decoder: 2.4112e-03, sindy-x: 3.8207e-03, sindy-z: 2.5471e-02, sindy-reg: 4.6856\n",
      "Epoch 8100\n",
      "  train loss: 2.3512e-04, decoder: 1.1762e-04, sindy-x: 6.7893e-04, sindy-z: 4.9602e-04, sindy-reg: 4.6735\n",
      "Epoch 8200\n",
      "  train loss: 2.2178e-04, decoder: 5.0141e-05, sindy-x: 7.3461e-04, sindy-z: 9.8182e-04, sindy-reg: 4.6638\n",
      "Epoch 8300\n",
      "  train loss: 9.3777e-04, decoder: 6.8792e-04, sindy-x: 7.0547e-04, sindy-z: 1.7930e-03, sindy-reg: 4.6397\n",
      "Epoch 8400\n",
      "  train loss: 7.6201e-04, decoder: 5.2482e-04, sindy-x: 7.0955e-04, sindy-z: 1.6624e-03, sindy-reg: 4.6393\n",
      "Epoch 8500\n",
      "  train loss: 1.2529e-03, decoder: 1.3024e-04, sindy-x: 1.4741e-03, sindy-z: 9.7523e-03, sindy-reg: 4.6065\n",
      "Epoch 8600\n",
      "  train loss: 1.8093e-04, decoder: 6.8170e-05, sindy-x: 8.1863e-04, sindy-z: 3.0895e-04, sindy-reg: 4.5857\n",
      "Epoch 8700\n",
      "  train loss: 3.4881e-04, decoder: 7.3941e-05, sindy-x: 9.4387e-04, sindy-z: 1.8048e-03, sindy-reg: 4.5762\n",
      "Epoch 8800\n",
      "  train loss: 2.8630e-04, decoder: 6.2659e-05, sindy-x: 7.5809e-04, sindy-z: 1.4783e-03, sindy-reg: 4.5405\n",
      "Epoch 8900\n",
      "  train loss: 1.2369e-04, decoder: 2.7919e-05, sindy-x: 6.0574e-04, sindy-z: 3.5198e-04, sindy-reg: 4.5384\n",
      "Epoch 9000\n",
      "  train loss: 1.0823e-04, decoder: 2.7060e-05, sindy-x: 6.1416e-04, sindy-z: 1.9752e-04, sindy-reg: 4.5385\n",
      "Epoch 9100\n",
      "  train loss: 1.8729e-04, decoder: 9.0915e-05, sindy-x: 5.8447e-04, sindy-z: 3.7930e-04, sindy-reg: 4.5269\n",
      "Epoch 9200\n",
      "  train loss: 1.3328e-04, decoder: 4.8979e-05, sindy-x: 6.5544e-04, sindy-z: 1.8754e-04, sindy-reg: 4.5086\n",
      "Epoch 9300\n",
      "  train loss: 6.3434e-04, decoder: 7.8535e-05, sindy-x: 2.1274e-03, sindy-z: 3.4307e-03, sindy-reg: 4.4942\n",
      "Epoch 9400\n",
      "  train loss: 5.7506e-04, decoder: 2.0861e-04, sindy-x: 9.9520e-04, sindy-z: 2.6693e-03, sindy-reg: 4.4904\n",
      "Epoch 9500\n",
      "  train loss: 1.0588e-04, decoder: 2.0546e-05, sindy-x: 6.3841e-04, sindy-z: 2.1497e-04, sindy-reg: 4.4782\n",
      "Epoch 9600\n",
      "  train loss: 1.2363e-04, decoder: 3.7403e-05, sindy-x: 5.9933e-04, sindy-z: 2.6291e-04, sindy-reg: 4.4728\n",
      "Epoch 9700\n",
      "  train loss: 5.4007e-04, decoder: 1.6355e-04, sindy-x: 1.2776e-03, sindy-z: 2.4875e-03, sindy-reg: 4.4540\n",
      "Epoch 9800\n",
      "  train loss: 1.1647e-04, decoder: 3.9497e-05, sindy-x: 5.9794e-04, sindy-z: 1.7180e-04, sindy-reg: 4.4467\n",
      "Epoch 9900\n",
      "  train loss: 1.5588e-04, decoder: 5.4653e-05, sindy-x: 6.2595e-04, sindy-z: 3.8628e-04, sindy-reg: 4.4391\n",
      "* Evaluating\n",
      "  Time: 16.26 s, Case: [0.84 0.96], Tol: 0.00051, Max Error: 0.006580\n",
      "  Update tolerance for error indicator from 0.00051 to 0.00060\n",
      "* Update Training set: add case [0.84 0.96]\n",
      "* Updating graph\n",
      "  Existing SINDys: 8, Create new SINDy: 9\n",
      "Epoch 10000\n",
      "  train loss: 5.4161e-03, decoder: 1.2821e-03, sindy-x: 3.7083e-03, sindy-z: 3.7631e-02, sindy-reg: 4.9756\n",
      "Epoch 10100\n",
      "  train loss: 1.5938e-04, decoder: 5.4944e-05, sindy-x: 6.8752e-04, sindy-z: 3.5684e-04, sindy-reg: 4.9660\n",
      "Epoch 10200\n",
      "  train loss: 1.6051e-04, decoder: 6.6439e-05, sindy-x: 6.4418e-04, sindy-z: 2.9655e-04, sindy-reg: 4.9516\n",
      "Epoch 10300\n",
      "  train loss: 3.6253e-04, decoder: 1.9518e-04, sindy-x: 1.0692e-03, sindy-z: 6.0434e-04, sindy-reg: 4.9351\n",
      "Epoch 10400\n",
      "  train loss: 1.1468e-04, decoder: 2.7132e-05, sindy-x: 6.6963e-04, sindy-z: 2.0582e-04, sindy-reg: 4.9228\n",
      "Epoch 10500\n",
      "  train loss: 1.0367e-03, decoder: 7.3104e-05, sindy-x: 1.5338e-03, sindy-z: 8.1020e-03, sindy-reg: 4.9017\n",
      "Epoch 10600\n",
      "  train loss: 1.6848e-04, decoder: 2.9980e-05, sindy-x: 8.0422e-04, sindy-z: 5.8082e-04, sindy-reg: 4.8984\n",
      "Epoch 10700\n",
      "  train loss: 2.0108e-04, decoder: 3.1748e-05, sindy-x: 7.2377e-04, sindy-z: 9.6955e-04, sindy-reg: 4.8858\n",
      "Epoch 10800\n",
      "  train loss: 4.8155e-04, decoder: 1.0004e-04, sindy-x: 8.9680e-04, sindy-z: 2.9183e-03, sindy-reg: 4.8662\n",
      "Epoch 10900\n",
      "  train loss: 1.2849e-04, decoder: 2.5092e-05, sindy-x: 7.0746e-04, sindy-z: 3.2652e-04, sindy-reg: 4.8600\n",
      "Epoch 11000\n",
      "  train loss: 2.6827e-04, decoder: 1.0822e-04, sindy-x: 7.5100e-04, sindy-z: 8.4957e-04, sindy-reg: 4.8504\n",
      "Epoch 11100\n",
      "  train loss: 3.9103e-04, decoder: 3.4310e-05, sindy-x: 9.6644e-04, sindy-z: 2.6008e-03, sindy-reg: 4.8428\n",
      "Epoch 11200\n",
      "  train loss: 1.8291e-04, decoder: 4.4206e-05, sindy-x: 6.2759e-04, sindy-z: 7.5949e-04, sindy-reg: 4.8231\n",
      "Epoch 11300\n",
      "  train loss: 1.2934e-04, decoder: 1.6400e-05, sindy-x: 6.2652e-04, sindy-z: 5.0290e-04, sindy-reg: 4.8009\n",
      "Epoch 11400\n",
      "  train loss: 1.7225e-04, decoder: 1.6215e-05, sindy-x: 5.8982e-04, sindy-z: 9.7057e-04, sindy-reg: 4.7934\n",
      "Epoch 11500\n",
      "  train loss: 6.1662e-04, decoder: 1.1300e-04, sindy-x: 8.9148e-04, sindy-z: 4.1448e-03, sindy-reg: 4.7819\n",
      "Epoch 11600\n",
      "  train loss: 2.6148e-04, decoder: 1.3901e-04, sindy-x: 6.2273e-04, sindy-z: 6.0197e-04, sindy-reg: 4.7766\n",
      "Epoch 11700\n",
      "  train loss: 3.3125e-04, decoder: 1.9761e-04, sindy-x: 8.0166e-04, sindy-z: 5.3480e-04, sindy-reg: 4.7476\n",
      "Epoch 11800\n",
      "  train loss: 9.7650e-05, decoder: 2.2708e-05, sindy-x: 5.7673e-04, sindy-z: 1.7270e-04, sindy-reg: 4.7387\n",
      "Epoch 11900\n",
      "  train loss: 9.1049e-05, decoder: 1.8028e-05, sindy-x: 5.8622e-04, sindy-z: 1.4399e-04, sindy-reg: 4.7284\n",
      "* Evaluating\n",
      "  Time: 17.55 s, Case: [0.73 0.95], Tol: 0.00060, Max Error: 0.003679\n",
      "  Update tolerance for error indicator from 0.00060 to 0.00038\n",
      "* Update Training set: add case [0.73 0.95]\n",
      "* Updating graph\n",
      "  Existing SINDys: 9, Create new SINDy: 10\n",
      "Epoch 12000\n",
      "  train loss: 9.2363e-03, decoder: 4.0751e-03, sindy-x: 7.9200e-03, sindy-z: 4.3693e-02, sindy-reg: 5.2455\n",
      "Epoch 12100\n",
      "  train loss: 1.0303e-04, decoder: 3.4908e-05, sindy-x: 5.0357e-04, sindy-z: 1.7767e-04, sindy-reg: 5.2366\n",
      "Epoch 12200\n",
      "  train loss: 3.9642e-04, decoder: 3.0840e-05, sindy-x: 7.8099e-04, sindy-z: 2.8748e-03, sindy-reg: 5.2269\n",
      "Epoch 12300\n",
      "  train loss: 2.6208e-04, decoder: 5.1483e-05, sindy-x: 8.6319e-04, sindy-z: 1.2427e-03, sindy-reg: 5.2131\n",
      "Epoch 12400\n",
      "  train loss: 2.8217e-04, decoder: 1.0385e-04, sindy-x: 7.7843e-04, sindy-z: 1.0048e-03, sindy-reg: 5.2052\n",
      "Epoch 12500\n",
      "  train loss: 9.5067e-05, decoder: 3.0803e-05, sindy-x: 4.9850e-04, sindy-z: 1.4414e-04, sindy-reg: 5.1907\n",
      "Epoch 12600\n",
      "  train loss: 1.7391e-04, decoder: 7.4001e-05, sindy-x: 5.8011e-04, sindy-z: 4.1899e-04, sindy-reg: 5.1831\n",
      "Epoch 12700\n",
      "  train loss: 1.2978e-04, decoder: 4.9305e-05, sindy-x: 4.5296e-04, sindy-z: 3.5174e-04, sindy-reg: 5.1695\n",
      "Epoch 12800\n",
      "  train loss: 5.3666e-04, decoder: 6.7235e-05, sindy-x: 6.0597e-04, sindy-z: 4.0882e-03, sindy-reg: 5.1555\n",
      "Epoch 12900\n",
      "  train loss: 3.0011e-04, decoder: 3.3731e-05, sindy-x: 6.6895e-04, sindy-z: 1.9949e-03, sindy-reg: 5.1419\n",
      "Epoch 13000\n",
      "  train loss: 2.8153e-04, decoder: 4.0198e-05, sindy-x: 5.7224e-04, sindy-z: 1.8411e-03, sindy-reg: 5.1295\n",
      "Epoch 13100\n",
      "  train loss: 4.2251e-04, decoder: 2.8938e-04, sindy-x: 9.5274e-04, sindy-z: 3.7850e-04, sindy-reg: 5.1139\n",
      "Epoch 13200\n",
      "  train loss: 1.6629e-04, decoder: 2.9601e-05, sindy-x: 5.9547e-04, sindy-z: 7.7142e-04, sindy-reg: 5.1056\n",
      "Epoch 13300\n",
      "  train loss: 3.2079e-04, decoder: 1.6019e-04, sindy-x: 5.2857e-04, sindy-z: 1.0774e-03, sindy-reg: 5.0817\n",
      "Epoch 13400\n",
      "  train loss: 2.9831e-04, decoder: 8.8460e-05, sindy-x: 6.4519e-04, sindy-z: 1.4533e-03, sindy-reg: 5.0737\n",
      "Epoch 13500\n",
      "  train loss: 1.5503e-04, decoder: 6.9683e-05, sindy-x: 4.8417e-04, sindy-z: 3.6930e-04, sindy-reg: 5.0625\n",
      "Epoch 13600\n",
      "  train loss: 7.2034e-05, decoder: 1.2578e-05, sindy-x: 3.6824e-04, sindy-z: 2.2631e-04, sindy-reg: 5.0483\n",
      "Epoch 13700\n",
      "  train loss: 9.5484e-05, decoder: 3.1432e-05, sindy-x: 3.9610e-04, sindy-z: 2.4442e-04, sindy-reg: 5.0422\n",
      "Epoch 13800\n",
      "  train loss: 1.1088e-04, decoder: 5.0911e-05, sindy-x: 4.2428e-04, sindy-z: 1.7537e-04, sindy-reg: 5.0273\n",
      "Epoch 13900\n",
      "  train loss: 1.4559e-04, decoder: 3.7603e-05, sindy-x: 4.2588e-04, sindy-z: 6.5394e-04, sindy-reg: 5.0141\n",
      "* Evaluating\n",
      "  Time: 15.75 s, Case: [0.86 1.05], Tol: 0.00038, Max Error: 0.003083\n",
      "  Update tolerance for error indicator from 0.00038 to 0.00091\n",
      "* Update Training set: add case [0.86 1.05]\n",
      "* Updating graph\n",
      "  Existing SINDys: 10, Create new SINDy: 11\n",
      "Epoch 14000\n",
      "  train loss: 6.4648e-03, decoder: 4.6762e-03, sindy-x: 9.0942e-03, sindy-z: 8.7922e-03, sindy-reg: 5.4972\n",
      "Epoch 14100\n",
      "  train loss: 3.3318e-04, decoder: 9.2402e-05, sindy-x: 1.1205e-03, sindy-z: 1.2872e-03, sindy-reg: 5.4671\n",
      "Epoch 14200\n",
      "  train loss: 1.1179e-04, decoder: 3.3628e-05, sindy-x: 4.5680e-04, sindy-z: 3.2483e-04, sindy-reg: 5.4550\n",
      "Epoch 14300\n",
      "  train loss: 1.8461e-04, decoder: 4.9583e-05, sindy-x: 4.0366e-04, sindy-z: 9.4661e-04, sindy-reg: 5.4495\n",
      "Epoch 14400\n",
      "  train loss: 9.1004e-05, decoder: 3.3495e-05, sindy-x: 4.1022e-04, sindy-z: 1.6487e-04, sindy-reg: 5.4392\n",
      "Epoch 14500\n",
      "  train loss: 1.8598e-04, decoder: 5.4616e-05, sindy-x: 5.5185e-04, sindy-z: 7.6182e-04, sindy-reg: 5.4261\n",
      "Epoch 14600\n",
      "  train loss: 2.1283e-04, decoder: 4.6903e-05, sindy-x: 5.3331e-04, sindy-z: 1.1259e-03, sindy-reg: 5.4124\n",
      "Epoch 14700\n",
      "  train loss: 1.4116e-04, decoder: 5.5168e-05, sindy-x: 5.9217e-04, sindy-z: 2.6778e-04, sindy-reg: 5.3961\n",
      "Epoch 14800\n",
      "  train loss: 7.7812e-05, decoder: 2.2212e-05, sindy-x: 4.0003e-04, sindy-z: 1.5597e-04, sindy-reg: 5.3910\n",
      "Epoch 14900\n",
      "  train loss: 1.1080e-04, decoder: 2.6486e-05, sindy-x: 4.1072e-04, sindy-z: 4.3244e-04, sindy-reg: 5.3748\n",
      "Epoch 15000\n",
      "  train loss: 1.2095e-04, decoder: 4.5030e-05, sindy-x: 5.3110e-04, sindy-z: 2.2807e-04, sindy-reg: 5.3616\n",
      "Epoch 15100\n",
      "  train loss: 3.6258e-04, decoder: 1.0015e-04, sindy-x: 5.5664e-04, sindy-z: 2.0677e-03, sindy-reg: 5.3497\n",
      "Epoch 15200\n",
      "  train loss: 7.3695e-05, decoder: 2.5827e-05, sindy-x: 3.7379e-04, sindy-z: 1.0489e-04, sindy-reg: 5.3439\n",
      "Epoch 15300\n",
      "  train loss: 2.0968e-04, decoder: 1.1303e-04, sindy-x: 5.7029e-04, sindy-z: 3.9616e-04, sindy-reg: 5.3298\n",
      "Epoch 15400\n",
      "  train loss: 4.4793e-04, decoder: 2.8616e-04, sindy-x: 4.2896e-04, sindy-z: 1.1887e-03, sindy-reg: 5.3135\n",
      "Epoch 15500\n",
      "  train loss: 2.5844e-04, decoder: 7.6769e-05, sindy-x: 4.6434e-04, sindy-z: 1.3524e-03, sindy-reg: 5.3043\n",
      "Epoch 15600\n",
      "  train loss: 3.5908e-04, decoder: 1.5653e-04, sindy-x: 6.8329e-04, sindy-z: 1.3422e-03, sindy-reg: 5.2791\n",
      "Epoch 15700\n",
      "  train loss: 2.1623e-04, decoder: 6.7844e-05, sindy-x: 6.2604e-04, sindy-z: 8.5783e-04, sindy-reg: 5.2669\n",
      "Epoch 15800\n",
      "  train loss: 1.5745e-04, decoder: 5.4959e-05, sindy-x: 4.8033e-04, sindy-z: 5.4457e-04, sindy-reg: 5.2499\n",
      "Epoch 15900\n",
      "  train loss: 1.9562e-04, decoder: 9.6670e-05, sindy-x: 5.2809e-04, sindy-z: 4.6141e-04, sindy-reg: 5.2317\n",
      "* Evaluating\n",
      "  Time: 16.11 s, Case: [0.89 0.95], Tol: 0.00091, Max Error: 0.002728\n",
      "  Update tolerance for error indicator from 0.00091 to 0.00110\n",
      "* Update Training set: add case [0.89 0.95]\n",
      "* Updating graph\n",
      "  Existing SINDys: 11, Create new SINDy: 12\n",
      "Epoch 16000\n",
      "  train loss: 2.0951e-03, decoder: 1.0440e-03, sindy-x: 3.6399e-03, sindy-z: 6.8711e-03, sindy-reg: 5.7340\n",
      "Epoch 16100\n",
      "  train loss: 1.0181e-04, decoder: 2.7224e-05, sindy-x: 4.6278e-04, sindy-z: 2.8306e-04, sindy-reg: 5.7022\n",
      "Epoch 16200\n",
      "  train loss: 8.8520e-05, decoder: 3.2304e-05, sindy-x: 4.1341e-04, sindy-z: 1.4876e-04, sindy-reg: 5.6875\n",
      "Epoch 16300\n",
      "  train loss: 1.2190e-04, decoder: 5.9761e-05, sindy-x: 4.7925e-04, sindy-z: 1.4211e-04, sindy-reg: 5.6698\n",
      "Epoch 16400\n",
      "  train loss: 8.1491e-05, decoder: 2.6504e-05, sindy-x: 4.0950e-04, sindy-z: 1.4036e-04, sindy-reg: 5.6517\n",
      "Epoch 16500\n",
      "  train loss: 4.4692e-04, decoder: 2.2430e-04, sindy-x: 4.8420e-04, sindy-z: 1.7420e-03, sindy-reg: 5.6354\n",
      "Epoch 16600\n",
      "  train loss: 1.8832e-04, decoder: 9.6834e-05, sindy-x: 4.5992e-04, sindy-z: 4.5498e-04, sindy-reg: 5.6284\n",
      "Epoch 16700\n",
      "  train loss: 9.0698e-05, decoder: 2.5523e-05, sindy-x: 4.0494e-04, sindy-z: 2.4682e-04, sindy-reg: 5.6077\n",
      "Epoch 16800\n",
      "  train loss: 1.3026e-04, decoder: 5.3305e-05, sindy-x: 4.0603e-04, sindy-z: 3.6356e-04, sindy-reg: 5.6035\n",
      "Epoch 16900\n",
      "  train loss: 1.1955e-04, decoder: 5.3580e-05, sindy-x: 4.3672e-04, sindy-z: 2.2296e-04, sindy-reg: 5.5782\n",
      "Epoch 17000\n",
      "  train loss: 1.8018e-04, decoder: 7.6121e-05, sindy-x: 7.3129e-04, sindy-z: 3.0929e-04, sindy-reg: 5.5588\n",
      "Epoch 17100\n",
      "  train loss: 2.4084e-04, decoder: 6.0909e-05, sindy-x: 4.9567e-04, sindy-z: 1.3037e-03, sindy-reg: 5.5460\n",
      "Epoch 17200\n",
      "  train loss: 1.2955e-04, decoder: 3.1107e-05, sindy-x: 4.8477e-04, sindy-z: 4.9971e-04, sindy-reg: 5.5312\n",
      "Epoch 17300\n",
      "  train loss: 1.3696e-04, decoder: 6.9388e-05, sindy-x: 5.0719e-04, sindy-z: 1.6852e-04, sindy-reg: 5.5186\n",
      "Epoch 17400\n",
      "  train loss: 1.3612e-04, decoder: 4.1847e-05, sindy-x: 5.2475e-04, sindy-z: 4.1800e-04, sindy-reg: 5.5006\n",
      "Epoch 17500\n",
      "  train loss: 2.6075e-04, decoder: 1.4498e-04, sindy-x: 5.3147e-04, sindy-z: 6.2622e-04, sindy-reg: 5.4870\n",
      "Epoch 17600\n",
      "  train loss: 3.9910e-04, decoder: 1.8578e-04, sindy-x: 5.5539e-04, sindy-z: 1.5778e-03, sindy-reg: 5.4746\n",
      "Epoch 17700\n",
      "  train loss: 4.4556e-04, decoder: 2.9514e-04, sindy-x: 5.8948e-04, sindy-z: 9.1474e-04, sindy-reg: 5.4665\n",
      "Epoch 17800\n",
      "  train loss: 4.9931e-04, decoder: 3.7843e-04, sindy-x: 5.4308e-04, sindy-z: 6.6575e-04, sindy-reg: 5.4475\n",
      "Epoch 17900\n",
      "  train loss: 1.6507e-04, decoder: 5.5269e-05, sindy-x: 5.6540e-04, sindy-z: 5.3257e-04, sindy-reg: 5.4310\n",
      "* Evaluating\n",
      "  Time: 15.08 s, Case: [0.84 0.91], Tol: 0.00110, Max Error: 0.002136\n",
      "  Update tolerance for error indicator from 0.00110 to 0.00048\n",
      "* Update Training set: add case [0.84 0.91]\n",
      "* Updating graph\n",
      "  Existing SINDys: 12, Create new SINDy: 13\n",
      "Epoch 18000\n",
      "  train loss: 1.1441e-02, decoder: 6.7728e-03, sindy-x: 1.4274e-02, sindy-z: 3.2412e-02, sindy-reg: 5.8634\n",
      "Epoch 18100\n",
      "  train loss: 6.2023e-05, decoder: 1.4371e-05, sindy-x: 3.6731e-04, sindy-z: 1.0921e-04, sindy-reg: 5.8556\n",
      "Epoch 18200\n",
      "  train loss: 1.5831e-04, decoder: 5.2665e-05, sindy-x: 7.7786e-04, sindy-z: 2.7855e-04, sindy-reg: 5.8602\n",
      "Epoch 18300\n",
      "  train loss: 3.5798e-04, decoder: 2.2756e-04, sindy-x: 9.9103e-04, sindy-z: 3.1315e-04, sindy-reg: 5.8415\n",
      "Epoch 18400\n",
      "  train loss: 1.3599e-04, decoder: 5.4750e-05, sindy-x: 4.2876e-04, sindy-z: 3.8364e-04, sindy-reg: 5.8336\n",
      "Epoch 18500\n",
      "  train loss: 4.9603e-04, decoder: 9.2414e-05, sindy-x: 1.3482e-03, sindy-z: 2.6880e-03, sindy-reg: 5.8178\n",
      "Epoch 18600\n",
      "  train loss: 1.6181e-04, decoder: 4.5702e-05, sindy-x: 4.9796e-04, sindy-z: 6.6308e-04, sindy-reg: 5.8067\n",
      "Epoch 18700\n",
      "  train loss: 1.4264e-04, decoder: 6.0654e-05, sindy-x: 4.6257e-04, sindy-z: 3.5726e-04, sindy-reg: 5.7898\n",
      "Epoch 18800\n",
      "  train loss: 1.9249e-04, decoder: 9.0264e-05, sindy-x: 4.7215e-04, sindy-z: 5.5010e-04, sindy-reg: 5.7726\n",
      "Epoch 18900\n",
      "  train loss: 2.0127e-04, decoder: 1.3706e-04, sindy-x: 4.4396e-04, sindy-z: 1.9817e-04, sindy-reg: 5.7553\n",
      "Epoch 19000\n",
      "  train loss: 8.6683e-05, decoder: 1.8650e-05, sindy-x: 3.8247e-04, sindy-z: 2.9785e-04, sindy-reg: 5.7353\n",
      "Epoch 19100\n",
      "  train loss: 1.2581e-04, decoder: 3.9263e-05, sindy-x: 4.0915e-04, sindy-z: 4.5636e-04, sindy-reg: 5.7215\n",
      "Epoch 19200\n",
      "  train loss: 6.5123e-05, decoder: 1.7446e-05, sindy-x: 3.6392e-04, sindy-z: 1.1285e-04, sindy-reg: 5.6986\n",
      "Epoch 19300\n",
      "  train loss: 2.5279e-04, decoder: 1.2745e-04, sindy-x: 4.1008e-04, sindy-z: 8.4329e-04, sindy-reg: 5.6707\n",
      "Epoch 19400\n",
      "  train loss: 1.1950e-04, decoder: 5.5456e-05, sindy-x: 3.5522e-04, sindy-z: 2.8518e-04, sindy-reg: 5.6539\n",
      "Epoch 19500\n",
      "  train loss: 1.0834e-04, decoder: 4.9814e-05, sindy-x: 3.4435e-04, sindy-z: 2.4092e-04, sindy-reg: 5.6373\n",
      "Epoch 19600\n",
      "  train loss: 2.5352e-04, decoder: 1.7512e-04, sindy-x: 3.6266e-04, sindy-z: 4.2134e-04, sindy-reg: 5.6156\n",
      "Epoch 19700\n",
      "  train loss: 2.1517e-04, decoder: 7.9905e-05, sindy-x: 4.5161e-04, sindy-z: 9.0104e-04, sindy-reg: 5.6160\n",
      "Epoch 19800\n",
      "  train loss: 1.3445e-04, decoder: 6.7256e-05, sindy-x: 4.7694e-04, sindy-z: 1.9495e-04, sindy-reg: 5.5865\n",
      "Epoch 19900\n",
      "  train loss: 5.8984e-05, decoder: 1.4552e-05, sindy-x: 3.4037e-04, sindy-z: 1.0395e-04, sindy-reg: 5.5879\n",
      "* Evaluating\n",
      "  Time: 14.93 s, Case: [0.74 0.91], Tol: 0.00048, Max Error: 0.001964\n",
      "  Update tolerance for error indicator from 0.00048 to 0.00030\n",
      "* Update Training set: add case [0.74 0.91]\n",
      "* Updating graph\n",
      "  Existing SINDys: 13, Create new SINDy: 14\n",
      "Epoch 20000\n",
      "  train loss: 7.9067e-03, decoder: 5.4917e-03, sindy-x: 7.1121e-03, sindy-z: 1.7038e-02, sindy-reg: 6.0015\n",
      "Epoch 20100\n",
      "  train loss: 1.0130e-04, decoder: 2.5289e-05, sindy-x: 4.4980e-04, sindy-z: 3.1033e-04, sindy-reg: 5.9957\n",
      "Epoch 20200\n",
      "  train loss: 9.3003e-05, decoder: 3.1807e-05, sindy-x: 4.0761e-04, sindy-z: 2.0435e-04, sindy-reg: 5.9849\n",
      "Epoch 20300\n",
      "  train loss: 2.4458e-04, decoder: 8.5624e-05, sindy-x: 3.8406e-04, sindy-z: 1.2055e-03, sindy-reg: 5.9765\n",
      "Epoch 20400\n",
      "  train loss: 9.7381e-05, decoder: 3.8919e-05, sindy-x: 3.8643e-04, sindy-z: 1.9819e-04, sindy-reg: 5.9565\n",
      "Epoch 20500\n",
      "  train loss: 1.0910e-04, decoder: 3.6152e-05, sindy-x: 3.7272e-04, sindy-z: 3.5674e-04, sindy-reg: 5.9375\n",
      "Epoch 20600\n",
      "  train loss: 8.2796e-05, decoder: 3.0943e-05, sindy-x: 3.7314e-04, sindy-z: 1.4539e-04, sindy-reg: 5.9305\n",
      "Epoch 20700\n",
      "  train loss: 1.9241e-04, decoder: 5.5762e-05, sindy-x: 7.2098e-04, sindy-z: 6.4555e-04, sindy-reg: 5.9183\n",
      "Epoch 20800\n",
      "  train loss: 4.3562e-04, decoder: 2.2288e-04, sindy-x: 7.4624e-04, sindy-z: 1.3811e-03, sindy-reg: 5.8988\n",
      "Epoch 20900\n",
      "  train loss: 2.4743e-04, decoder: 1.2262e-04, sindy-x: 4.2936e-04, sindy-z: 8.1867e-04, sindy-reg: 5.8848\n",
      "Epoch 21000\n",
      "  train loss: 9.4945e-05, decoder: 3.9782e-05, sindy-x: 4.4403e-04, sindy-z: 1.0760e-04, sindy-reg: 5.8763\n",
      "Epoch 21100\n",
      "  train loss: 1.3999e-04, decoder: 6.2768e-05, sindy-x: 3.7253e-04, sindy-z: 3.9969e-04, sindy-reg: 5.8571\n",
      "Epoch 21200\n",
      "  train loss: 1.2171e-04, decoder: 7.3960e-05, sindy-x: 3.2837e-04, sindy-z: 1.4914e-04, sindy-reg: 5.8398\n",
      "Epoch 21300\n",
      "  train loss: 7.2315e-05, decoder: 2.0579e-05, sindy-x: 3.3504e-04, sindy-z: 1.8233e-04, sindy-reg: 5.8293\n",
      "Epoch 21400\n",
      "  train loss: 5.3099e-04, decoder: 2.9178e-04, sindy-x: 1.0007e-03, sindy-z: 1.3915e-03, sindy-reg: 5.8199\n",
      "Epoch 21500\n",
      "  train loss: 9.7684e-05, decoder: 2.9079e-05, sindy-x: 4.1171e-04, sindy-z: 2.7434e-04, sindy-reg: 5.8057\n",
      "Epoch 21600\n",
      "  train loss: 8.3169e-05, decoder: 2.1485e-05, sindy-x: 3.4474e-04, sindy-z: 2.7210e-04, sindy-reg: 5.7939\n",
      "Epoch 21700\n",
      "  train loss: 9.5002e-05, decoder: 4.5491e-05, sindy-x: 3.5623e-04, sindy-z: 1.3889e-04, sindy-reg: 5.7837\n",
      "Epoch 21800\n",
      "  train loss: 8.2207e-05, decoder: 2.4781e-05, sindy-x: 3.9838e-04, sindy-z: 1.7588e-04, sindy-reg: 5.7687\n",
      "Epoch 21900\n",
      "  train loss: 1.6857e-04, decoder: 9.5202e-05, sindy-x: 4.7428e-04, sindy-z: 2.5941e-04, sindy-reg: 5.7539\n",
      "* Evaluating\n",
      "  Time: 15.02 s, Case: [0.7  1.02], Tol: 0.00030, Max Error: 0.001492\n",
      "  Update tolerance for error indicator from 0.00030 to 0.00047\n",
      "* Update Training set: add case [0.7  1.02]\n",
      "* Updating graph\n",
      "  Existing SINDys: 14, Create new SINDy: 15\n",
      "Epoch 22000\n",
      "  train loss: 1.1290e-02, decoder: 7.3799e-03, sindy-x: 1.2164e-02, sindy-z: 2.6941e-02, sindy-reg: 6.1231\n",
      "Epoch 22100\n",
      "  train loss: 6.8092e-05, decoder: 2.2543e-05, sindy-x: 3.4715e-04, sindy-z: 1.0834e-04, sindy-reg: 6.1180\n",
      "Epoch 22200\n",
      "  train loss: 2.4277e-04, decoder: 8.1664e-05, sindy-x: 7.1730e-04, sindy-z: 8.9375e-04, sindy-reg: 6.1077\n",
      "Epoch 22300\n",
      "  train loss: 8.7292e-05, decoder: 3.0683e-05, sindy-x: 3.5316e-04, sindy-z: 2.1293e-04, sindy-reg: 6.0961\n",
      "Epoch 22400\n",
      "  train loss: 4.3866e-04, decoder: 3.5614e-04, sindy-x: 4.0182e-04, sindy-z: 4.2344e-04, sindy-reg: 6.0805\n",
      "Epoch 22500\n",
      "  train loss: 2.2281e-04, decoder: 3.3215e-05, sindy-x: 7.9976e-04, sindy-z: 1.0961e-03, sindy-reg: 6.0628\n",
      "Epoch 22600\n",
      "  train loss: 1.6124e-04, decoder: 4.7571e-05, sindy-x: 4.4460e-04, sindy-z: 6.9205e-04, sindy-reg: 6.0516\n",
      "Epoch 22700\n",
      "  train loss: 7.0106e-05, decoder: 1.5400e-05, sindy-x: 3.4882e-04, sindy-z: 1.9825e-04, sindy-reg: 6.0369\n",
      "Epoch 22800\n",
      "  train loss: 1.2648e-04, decoder: 3.8731e-05, sindy-x: 4.9966e-04, sindy-z: 3.7787e-04, sindy-reg: 6.0273\n",
      "Epoch 22900\n",
      "  train loss: 1.1735e-04, decoder: 4.4627e-05, sindy-x: 3.7200e-04, sindy-z: 3.5519e-04, sindy-reg: 6.0109\n",
      "Epoch 23000\n",
      "  train loss: 1.0129e-04, decoder: 5.3679e-05, sindy-x: 3.2248e-04, sindy-z: 1.5363e-04, sindy-reg: 5.9945\n",
      "Epoch 23100\n",
      "  train loss: 6.4796e-05, decoder: 1.5778e-05, sindy-x: 3.4032e-04, sindy-z: 1.4986e-04, sindy-reg: 5.9842\n",
      "Epoch 23200\n",
      "  train loss: 1.3189e-04, decoder: 2.6751e-05, sindy-x: 3.9247e-04, sindy-z: 6.5891e-04, sindy-reg: 5.9677\n",
      "Epoch 23300\n",
      "  train loss: 1.1254e-04, decoder: 2.4776e-05, sindy-x: 3.5001e-04, sindy-z: 5.2759e-04, sindy-reg: 5.9514\n",
      "Epoch 23400\n",
      "  train loss: 3.0373e-04, decoder: 1.3526e-04, sindy-x: 1.1077e-03, sindy-z: 5.7705e-04, sindy-reg: 5.9413\n",
      "Epoch 23500\n",
      "  train loss: 8.1802e-05, decoder: 3.9019e-05, sindy-x: 3.1938e-04, sindy-z: 1.0844e-04, sindy-reg: 5.9207\n",
      "Epoch 23600\n",
      "  train loss: 9.5998e-05, decoder: 2.2354e-05, sindy-x: 3.9414e-04, sindy-z: 3.4229e-04, sindy-reg: 5.9109\n",
      "Epoch 23700\n",
      "  train loss: 1.6715e-04, decoder: 8.9901e-05, sindy-x: 5.5827e-04, sindy-z: 2.1420e-04, sindy-reg: 5.9000\n",
      "Epoch 23800\n",
      "  train loss: 2.1534e-04, decoder: 1.5571e-04, sindy-x: 3.5240e-04, sindy-z: 2.4387e-04, sindy-reg: 5.8884\n",
      "Epoch 23900\n",
      "  train loss: 1.1992e-04, decoder: 7.4393e-05, sindy-x: 3.4005e-04, sindy-z: 1.1518e-04, sindy-reg: 5.8709\n",
      "* Evaluating\n",
      "  Time: 15.69 s, Case: [0.75 1.06], Tol: 0.00047, Max Error: 0.001325\n",
      "  Update tolerance for error indicator from 0.00047 to 0.00054\n",
      "* Update Training set: add case [0.75 1.06]\n",
      "* Updating graph\n",
      "  Existing SINDys: 15, Create new SINDy: 16\n",
      "Epoch 24000\n",
      "  train loss: 5.0230e-03, decoder: 2.9191e-03, sindy-x: 9.9891e-03, sindy-z: 1.1050e-02, sindy-reg: 6.2247\n",
      "Epoch 24100\n",
      "  train loss: 1.4901e-04, decoder: 6.7801e-05, sindy-x: 4.0849e-04, sindy-z: 4.0360e-04, sindy-reg: 6.2224\n",
      "Epoch 24200\n",
      "  train loss: 5.5790e-05, decoder: 1.4597e-05, sindy-x: 3.0868e-04, sindy-z: 1.0325e-04, sindy-reg: 6.1941\n",
      "Epoch 24300\n",
      "  train loss: 1.9525e-04, decoder: 5.7215e-05, sindy-x: 5.4032e-04, sindy-z: 8.4006e-04, sindy-reg: 6.1880\n",
      "Epoch 24400\n",
      "  train loss: 1.1763e-04, decoder: 5.3077e-05, sindy-x: 3.5305e-04, sindy-z: 2.9244e-04, sindy-reg: 6.1741\n",
      "Epoch 24500\n",
      "  train loss: 1.4181e-04, decoder: 6.3966e-05, sindy-x: 3.2718e-04, sindy-z: 4.5127e-04, sindy-reg: 6.1556\n",
      "Epoch 24600\n",
      "  train loss: 2.7180e-04, decoder: 1.7530e-04, sindy-x: 4.9154e-04, sindy-z: 4.7348e-04, sindy-reg: 6.1449\n",
      "Epoch 24700\n",
      "  train loss: 9.1826e-05, decoder: 2.8261e-05, sindy-x: 3.4119e-04, sindy-z: 2.9446e-04, sindy-reg: 6.1352\n",
      "Epoch 24800\n",
      "  train loss: 2.5575e-04, decoder: 9.8694e-05, sindy-x: 4.6897e-04, sindy-z: 1.1015e-03, sindy-reg: 6.1151\n",
      "Epoch 24900\n",
      "  train loss: 2.0207e-04, decoder: 1.1104e-04, sindy-x: 4.6575e-04, sindy-z: 4.4459e-04, sindy-reg: 6.1024\n",
      "Epoch 25000\n",
      "  train loss: 8.1022e-05, decoder: 2.4956e-05, sindy-x: 3.5076e-04, sindy-z: 2.0990e-04, sindy-reg: 6.0914\n",
      "Epoch 25100\n",
      "  train loss: 6.9407e-05, decoder: 2.3698e-05, sindy-x: 3.2831e-04, sindy-z: 1.2878e-04, sindy-reg: 6.0767\n",
      "Epoch 25200\n",
      "  train loss: 2.4654e-04, decoder: 1.0560e-04, sindy-x: 7.4046e-04, sindy-z: 6.6894e-04, sindy-reg: 6.0615\n",
      "Epoch 25300\n",
      "  train loss: 9.5461e-05, decoder: 2.2564e-05, sindy-x: 3.3777e-04, sindy-z: 3.9120e-04, sindy-reg: 6.0433\n",
      "Epoch 25400\n",
      "  train loss: 1.1996e-04, decoder: 5.9069e-05, sindy-x: 3.9552e-04, sindy-z: 2.1340e-04, sindy-reg: 6.0234\n",
      "Epoch 25500\n",
      "  train loss: 8.4680e-05, decoder: 3.4105e-05, sindy-x: 3.6643e-04, sindy-z: 1.3932e-04, sindy-reg: 6.0143\n",
      "Epoch 25600\n",
      "  train loss: 1.0462e-04, decoder: 2.5979e-05, sindy-x: 3.3700e-04, sindy-z: 4.4937e-04, sindy-reg: 6.0002\n",
      "Epoch 25700\n",
      "  train loss: 1.0365e-04, decoder: 4.2753e-05, sindy-x: 3.7577e-04, sindy-z: 2.3320e-04, sindy-reg: 5.9885\n",
      "Epoch 25800\n",
      "  train loss: 1.4574e-04, decoder: 6.8802e-05, sindy-x: 4.9323e-04, sindy-z: 2.7612e-04, sindy-reg: 5.9793\n",
      "Epoch 25900\n",
      "  train loss: 9.5424e-05, decoder: 3.9186e-05, sindy-x: 3.1124e-04, sindy-z: 2.5113e-04, sindy-reg: 5.9634\n",
      "* Evaluating\n",
      "  Time: 16.97 s, Case: [0.81 1.02], Tol: 0.00054, Max Error: 0.001025\n",
      "  Update tolerance for error indicator from 0.00054 to 0.00049\n",
      "* Update Training set: add case [0.81 1.02]\n",
      "* Updating graph\n",
      "  Existing SINDys: 16, Create new SINDy: 17\n",
      "Epoch 26000\n",
      "  train loss: 6.6360e-03, decoder: 5.1007e-03, sindy-x: 2.9250e-03, sindy-z: 1.2427e-02, sindy-reg: 6.2952\n",
      "Epoch 26100\n",
      "  train loss: 3.0308e-04, decoder: 6.9582e-05, sindy-x: 7.3783e-04, sindy-z: 1.5972e-03, sindy-reg: 6.4639\n",
      "Epoch 26200\n",
      "  train loss: 1.0555e-03, decoder: 6.3900e-04, sindy-x: 2.4054e-03, sindy-z: 1.7598e-03, sindy-reg: 6.5624\n",
      "Epoch 26300\n",
      "  train loss: 7.5992e-04, decoder: 4.8879e-04, sindy-x: 1.7739e-03, sindy-z: 9.3741e-04, sindy-reg: 6.5959\n",
      "Epoch 26400\n",
      "  train loss: 1.1119e-04, decoder: 3.1214e-05, sindy-x: 5.3742e-04, sindy-z: 2.6232e-04, sindy-reg: 6.5516\n",
      "Epoch 26500\n",
      "  train loss: 6.5488e-05, decoder: 2.3762e-05, sindy-x: 3.2050e-04, sindy-z: 9.6756e-05, sindy-reg: 6.3358\n",
      "Epoch 26600\n",
      "  train loss: 1.8916e-04, decoder: 8.3592e-05, sindy-x: 4.3827e-04, sindy-z: 6.1743e-04, sindy-reg: 6.3061\n",
      "Epoch 26700\n",
      "  train loss: 2.5629e-04, decoder: 6.0357e-05, sindy-x: 6.6053e-04, sindy-z: 1.2988e-03, sindy-reg: 6.2546\n",
      "Epoch 26800\n",
      "  train loss: 1.4933e-04, decoder: 3.5503e-05, sindy-x: 3.3476e-04, sindy-z: 8.0348e-04, sindy-reg: 6.2026\n",
      "Epoch 26900\n",
      "  train loss: 1.1100e-04, decoder: 4.6079e-05, sindy-x: 3.1627e-04, sindy-z: 3.3294e-04, sindy-reg: 6.1908\n",
      "Epoch 27000\n",
      "  train loss: 1.0925e-04, decoder: 3.0776e-05, sindy-x: 5.6615e-04, sindy-z: 2.1856e-04, sindy-reg: 6.1213\n",
      "Epoch 27100\n",
      "  train loss: 7.6515e-05, decoder: 2.5011e-05, sindy-x: 3.3324e-04, sindy-z: 1.8181e-04, sindy-reg: 6.1139\n",
      "Epoch 27200\n",
      "  train loss: 1.6994e-04, decoder: 9.2025e-05, sindy-x: 4.9298e-04, sindy-z: 2.8619e-04, sindy-reg: 6.0802\n",
      "Epoch 27300\n",
      "  train loss: 1.8542e-04, decoder: 1.0374e-04, sindy-x: 3.8737e-04, sindy-z: 4.2940e-04, sindy-reg: 6.0469\n",
      "Epoch 27400\n",
      "  train loss: 1.0958e-04, decoder: 5.1784e-05, sindy-x: 4.0650e-04, sindy-z: 1.7142e-04, sindy-reg: 6.0391\n",
      "Epoch 27500\n",
      "  train loss: 1.0735e-04, decoder: 4.4915e-05, sindy-x: 3.1294e-04, sindy-z: 3.1144e-04, sindy-reg: 6.0361\n",
      "Epoch 27600\n",
      "  train loss: 5.8846e-05, decoder: 1.9668e-05, sindy-x: 2.8902e-04, sindy-z: 1.0276e-04, sindy-reg: 5.9927\n",
      "Epoch 27700\n",
      "  train loss: 6.3027e-05, decoder: 2.3227e-05, sindy-x: 2.8975e-04, sindy-z: 1.0825e-04, sindy-reg: 5.9937\n",
      "Epoch 27800\n",
      "  train loss: 2.3767e-04, decoder: 1.6238e-04, sindy-x: 3.5909e-04, sindy-z: 3.9384e-04, sindy-reg: 5.9584\n",
      "Epoch 27900\n",
      "  train loss: 7.6366e-05, decoder: 2.7578e-05, sindy-x: 3.4753e-04, sindy-z: 1.4034e-04, sindy-reg: 5.9413\n",
      "* Evaluating\n",
      "  Time: 18.19 s, Case: [0.85 1.1 ], Tol: 0.00049, Max Error: 0.000839\n",
      "  Update tolerance for error indicator from 0.00049 to 0.00090\n",
      "* Update Training set: add case [0.85 1.1 ]\n",
      "  Max error indicator <= Tol! Current subset ratio 99.8%\n",
      "* Updating graph\n",
      "  Existing SINDys: 17, Create new SINDy: 18\n",
      "Epoch 28000\n",
      "  train loss: 5.1445e-03, decoder: 4.2712e-03, sindy-x: 1.9577e-03, sindy-z: 6.7763e-03, sindy-reg: 6.2847\n",
      "Epoch 28100\n",
      "  train loss: 9.3961e-05, decoder: 3.8494e-05, sindy-x: 3.5425e-04, sindy-z: 2.0042e-04, sindy-reg: 6.2829\n",
      "Epoch 28200\n",
      "  train loss: 1.2293e-04, decoder: 6.8665e-05, sindy-x: 3.2090e-04, sindy-z: 2.2170e-04, sindy-reg: 6.2753\n",
      "Epoch 28300\n",
      "  train loss: 1.2483e-04, decoder: 5.9679e-05, sindy-x: 3.4296e-04, sindy-z: 3.0850e-04, sindy-reg: 6.2543\n",
      "Epoch 28400\n",
      "  train loss: 2.6983e-04, decoder: 1.0525e-04, sindy-x: 9.8071e-04, sindy-z: 6.6515e-04, sindy-reg: 6.2426\n",
      "Epoch 28500\n",
      "  train loss: 8.7059e-05, decoder: 4.1987e-05, sindy-x: 3.1098e-04, sindy-z: 1.3974e-04, sindy-reg: 6.2206\n",
      "Epoch 28600\n",
      "  train loss: 1.2595e-04, decoder: 6.1863e-05, sindy-x: 3.6708e-04, sindy-z: 2.7380e-04, sindy-reg: 6.2182\n",
      "Epoch 28700\n",
      "  train loss: 1.1907e-04, decoder: 3.8424e-05, sindy-x: 4.4069e-04, sindy-z: 3.6581e-04, sindy-reg: 6.2243\n",
      "Epoch 28800\n",
      "  train loss: 2.6449e-04, decoder: 1.4326e-04, sindy-x: 5.8926e-04, sindy-z: 6.2302e-04, sindy-reg: 6.1926\n",
      "Epoch 28900\n",
      "  train loss: 6.2025e-05, decoder: 2.0665e-05, sindy-x: 3.2227e-04, sindy-z: 9.1328e-05, sindy-reg: 6.1536\n",
      "Epoch 29000\n",
      "  train loss: 2.1703e-04, decoder: 1.1143e-04, sindy-x: 3.6989e-04, sindy-z: 6.8606e-04, sindy-reg: 6.1525\n",
      "Epoch 29100\n",
      "  train loss: 3.9112e-04, decoder: 2.3522e-04, sindy-x: 7.0109e-04, sindy-z: 8.5789e-04, sindy-reg: 6.1255\n",
      "Epoch 29200\n",
      "  train loss: 9.6718e-05, decoder: 3.8669e-05, sindy-x: 3.8283e-04, sindy-z: 1.9766e-04, sindy-reg: 6.1185\n",
      "Epoch 29300\n",
      "  train loss: 7.0348e-05, decoder: 2.2520e-05, sindy-x: 3.6226e-04, sindy-z: 1.1602e-04, sindy-reg: 6.0998\n",
      "Epoch 29400\n",
      "  train loss: 9.2191e-05, decoder: 3.7471e-05, sindy-x: 3.6092e-04, sindy-z: 1.8628e-04, sindy-reg: 6.1161\n",
      "Epoch 29500\n",
      "  train loss: 1.7026e-04, decoder: 4.5402e-05, sindy-x: 4.3787e-04, sindy-z: 8.1073e-04, sindy-reg: 6.0709\n",
      "Epoch 29600\n",
      "  train loss: 2.9109e-04, decoder: 1.8280e-04, sindy-x: 5.4952e-04, sindy-z: 5.3347e-04, sindy-reg: 6.0667\n",
      "Epoch 29700\n",
      "  train loss: 9.3380e-05, decoder: 2.9335e-05, sindy-x: 3.2127e-04, sindy-z: 3.1918e-04, sindy-reg: 6.0487\n",
      "Epoch 29800\n",
      "  train loss: 4.5939e-04, decoder: 3.4337e-04, sindy-x: 8.2086e-04, sindy-z: 3.3930e-04, sindy-reg: 6.0436\n",
      "Epoch 29900\n",
      "  train loss: 9.3794e-05, decoder: 2.9057e-05, sindy-x: 3.1456e-04, sindy-z: 3.3281e-04, sindy-reg: 6.0203\n",
      "* Evaluating\n",
      "  Time: 31.55 s, Case: [0.9  1.05], Tol: 0.00090, Max Error: 0.000727\n",
      "  Update tolerance for error indicator from 0.00090 to 0.00081\n",
      "* Update Training set: add case [0.9  1.05]\n",
      "  Max error indicator <= Tol! Current subset ratio 100.0%\n",
      "* Updating graph\n",
      "  Existing SINDys: 18, Create new SINDy: 19\n",
      "Epoch 30000\n",
      "  train loss: 7.5440e-03, decoder: 5.5667e-03, sindy-x: 6.5894e-03, sindy-z: 1.3184e-02, sindy-reg: 6.3316\n",
      "Epoch 30100\n",
      "  train loss: 6.0039e-05, decoder: 1.5861e-05, sindy-x: 2.9660e-04, sindy-z: 1.4517e-04, sindy-reg: 6.3533\n",
      "Epoch 30200\n",
      "  train loss: 1.7976e-04, decoder: 8.7080e-05, sindy-x: 7.3259e-04, sindy-z: 1.9421e-04, sindy-reg: 6.3160\n",
      "Epoch 30300\n",
      "  train loss: 1.1435e-04, decoder: 2.8471e-05, sindy-x: 3.3270e-04, sindy-z: 5.2613e-04, sindy-reg: 6.3093\n",
      "Epoch 30400\n",
      "  train loss: 1.2985e-03, decoder: 4.8371e-04, sindy-x: 8.0944e-04, sindy-z: 7.3381e-03, sindy-reg: 6.3212\n",
      "Epoch 30500\n",
      "  train loss: 4.2992e-04, decoder: 3.2669e-04, sindy-x: 6.7721e-04, sindy-z: 3.5509e-04, sindy-reg: 6.3171\n",
      "Epoch 30600\n",
      "  train loss: 7.7869e-05, decoder: 2.3332e-05, sindy-x: 3.4215e-04, sindy-z: 2.0321e-04, sindy-reg: 6.3264\n",
      "Epoch 30700\n",
      "  train loss: 1.0946e-04, decoder: 3.3882e-05, sindy-x: 3.7024e-04, sindy-z: 3.8553e-04, sindy-reg: 6.3401\n",
      "Epoch 30800\n",
      "  train loss: 1.0693e-04, decoder: 5.9219e-05, sindy-x: 3.5439e-04, sindy-z: 1.2270e-04, sindy-reg: 6.2761\n",
      "Epoch 30900\n",
      "  train loss: 4.6153e-04, decoder: 2.1519e-04, sindy-x: 1.3878e-03, sindy-z: 1.0757e-03, sindy-reg: 6.2411\n",
      "Epoch 31000\n",
      "  train loss: 1.2214e-04, decoder: 3.5272e-05, sindy-x: 3.6248e-04, sindy-z: 5.0623e-04, sindy-reg: 6.2267\n",
      "Epoch 31100\n",
      "  train loss: 1.0755e-04, decoder: 5.5264e-05, sindy-x: 3.0284e-04, sindy-z: 2.2005e-04, sindy-reg: 6.2055\n",
      "Epoch 31200\n",
      "  train loss: 1.1249e-04, decoder: 3.8303e-05, sindy-x: 4.7166e-04, sindy-z: 2.7018e-04, sindy-reg: 6.1575\n",
      "Epoch 31300\n",
      "  train loss: 2.1956e-04, decoder: 1.3460e-04, sindy-x: 6.1399e-04, sindy-z: 2.3557e-04, sindy-reg: 6.1422\n",
      "Epoch 31400\n",
      "  train loss: 9.7897e-05, decoder: 4.5664e-05, sindy-x: 3.7035e-04, sindy-z: 1.5198e-04, sindy-reg: 6.1407\n",
      "Epoch 31500\n",
      "  train loss: 1.3900e-04, decoder: 8.3889e-05, sindy-x: 3.6555e-04, sindy-z: 1.8556e-04, sindy-reg: 6.0960\n",
      "Epoch 31600\n",
      "  train loss: 1.5622e-04, decoder: 6.0528e-05, sindy-x: 6.1381e-04, sindy-z: 3.4315e-04, sindy-reg: 6.0792\n",
      "Epoch 31700\n",
      "  train loss: 1.0444e-04, decoder: 4.6863e-05, sindy-x: 3.4204e-04, sindy-z: 2.3374e-04, sindy-reg: 6.0738\n",
      "Epoch 31800\n",
      "  train loss: 1.2888e-04, decoder: 6.2451e-05, sindy-x: 4.7748e-04, sindy-z: 1.8680e-04, sindy-reg: 6.0443\n",
      "Epoch 31900\n",
      "  train loss: 2.6349e-04, decoder: 1.3974e-04, sindy-x: 6.0914e-04, sindy-z: 6.2844e-04, sindy-reg: 6.0488\n",
      "* Evaluating\n",
      "  Time: 34.44 s, Case: [0.85 1.01], Tol: 0.00081, Max Error: 0.000652\n",
      "  Update tolerance for error indicator from 0.00081 to 0.00064\n",
      "* Update Training set: add case [0.85 1.01]\n",
      "* Updating graph\n",
      "  Existing SINDys: 19, Create new SINDy: 20\n",
      "Epoch 32000\n",
      "  train loss: 8.0989e-03, decoder: 5.7945e-03, sindy-x: 7.5958e-03, sindy-z: 1.5448e-02, sindy-reg: 6.3376\n",
      "Epoch 32100\n",
      "  train loss: 1.9172e-04, decoder: 6.4474e-05, sindy-x: 3.7926e-04, sindy-z: 8.9319e-04, sindy-reg: 6.3600\n",
      "Epoch 32200\n",
      "  train loss: 9.6849e-05, decoder: 3.2586e-05, sindy-x: 3.8056e-04, sindy-z: 2.6206e-04, sindy-reg: 6.2865\n",
      "Epoch 32300\n",
      "  train loss: 1.0806e-04, decoder: 3.9569e-05, sindy-x: 4.1656e-04, sindy-z: 2.6840e-04, sindy-reg: 6.2695\n",
      "Epoch 32400\n",
      "  train loss: 1.1221e-04, decoder: 4.2749e-05, sindy-x: 3.5306e-04, sindy-z: 3.4150e-04, sindy-reg: 6.2307\n",
      "Epoch 32500\n",
      "  train loss: 8.3878e-05, decoder: 2.8594e-05, sindy-x: 3.9155e-04, sindy-z: 1.6129e-04, sindy-reg: 6.2258\n",
      "Epoch 32600\n",
      "  train loss: 2.9991e-04, decoder: 1.4088e-04, sindy-x: 4.6752e-04, sindy-z: 1.1228e-03, sindy-reg: 6.2058\n",
      "Epoch 32700\n",
      "  train loss: 1.0653e-04, decoder: 3.4019e-05, sindy-x: 3.9523e-04, sindy-z: 3.2985e-04, sindy-reg: 6.1836\n",
      "Epoch 32800\n",
      "  train loss: 1.4010e-04, decoder: 6.7655e-05, sindy-x: 4.0764e-04, sindy-z: 3.1678e-04, sindy-reg: 6.1706\n",
      "Epoch 32900\n",
      "  train loss: 1.5529e-04, decoder: 8.5509e-05, sindy-x: 4.4569e-04, sindy-z: 2.5211e-04, sindy-reg: 6.1525\n",
      "Epoch 33000\n",
      "  train loss: 8.2612e-05, decoder: 2.6051e-05, sindy-x: 3.1067e-04, sindy-z: 2.5493e-04, sindy-reg: 6.1502\n",
      "Epoch 33100\n",
      "  train loss: 2.5849e-04, decoder: 1.5442e-04, sindy-x: 4.5843e-04, sindy-z: 5.8230e-04, sindy-reg: 6.1119\n",
      "Epoch 33200\n",
      "  train loss: 1.1787e-04, decoder: 4.3837e-05, sindy-x: 3.6828e-04, sindy-z: 3.7200e-04, sindy-reg: 6.0704\n",
      "Epoch 33300\n",
      "  train loss: 7.2774e-05, decoder: 2.8852e-05, sindy-x: 3.3097e-04, sindy-z: 1.0826e-04, sindy-reg: 6.0607\n",
      "Epoch 33400\n",
      "  train loss: 1.8581e-04, decoder: 8.9339e-05, sindy-x: 6.2631e-04, sindy-z: 3.3836e-04, sindy-reg: 6.0747\n",
      "Epoch 33500\n",
      "  train loss: 1.1803e-04, decoder: 4.4601e-05, sindy-x: 3.6596e-04, sindy-z: 3.6834e-04, sindy-reg: 6.0440\n",
      "Epoch 33600\n",
      "  train loss: 9.0334e-05, decoder: 3.4946e-05, sindy-x: 3.4036e-04, sindy-z: 2.1352e-04, sindy-reg: 6.0165\n",
      "Epoch 33700\n",
      "  train loss: 2.8232e-04, decoder: 1.7400e-04, sindy-x: 5.8276e-04, sindy-z: 5.0038e-04, sindy-reg: 6.0100\n",
      "Epoch 33800\n",
      "  train loss: 1.1045e-04, decoder: 4.7923e-05, sindy-x: 3.7903e-04, sindy-z: 2.4622e-04, sindy-reg: 6.0520\n",
      "Epoch 33900\n",
      "  train loss: 1.6297e-04, decoder: 5.3218e-05, sindy-x: 7.3374e-04, sindy-z: 3.6379e-04, sindy-reg: 6.0452\n",
      "* Evaluating\n",
      "  Time: 34.73 s, Case: [0.87 0.92], Tol: 0.00064, Max Error: 0.000936\n",
      "  Update tolerance for error indicator from 0.00064 to 0.00023\n",
      "* Update Training set: add case [0.87 0.92]\n",
      "* Updating graph\n",
      "  Existing SINDys: 20, Create new SINDy: 21\n",
      "Epoch 34000\n",
      "  train loss: 3.3306e-03, decoder: 1.4438e-03, sindy-x: 4.1471e-03, sindy-z: 1.4721e-02, sindy-reg: 6.2825\n",
      "Epoch 34100\n",
      "  train loss: 1.3443e-04, decoder: 5.0431e-05, sindy-x: 3.8186e-04, sindy-z: 4.5813e-04, sindy-reg: 6.2988\n",
      "Epoch 34200\n",
      "  train loss: 5.1796e-04, decoder: 2.5335e-04, sindy-x: 9.7924e-04, sindy-z: 1.6669e-03, sindy-reg: 6.3183\n",
      "Epoch 34300\n",
      "  train loss: 4.3960e-04, decoder: 2.8091e-04, sindy-x: 5.6818e-04, sindy-z: 1.0188e-03, sindy-reg: 6.3540\n",
      "Epoch 34400\n",
      "  train loss: 2.7391e-04, decoder: 9.5636e-05, sindy-x: 6.1812e-04, sindy-z: 1.1646e-03, sindy-reg: 6.3790\n",
      "Epoch 34500\n",
      "  train loss: 3.9590e-04, decoder: 1.3163e-04, sindy-x: 5.8903e-04, sindy-z: 2.0537e-03, sindy-reg: 6.3374\n",
      "Epoch 34600\n",
      "  train loss: 4.5524e-04, decoder: 1.4328e-04, sindy-x: 9.9861e-04, sindy-z: 2.1209e-03, sindy-reg: 6.3698\n",
      "Epoch 34700\n",
      "  train loss: 3.6202e-04, decoder: 1.9255e-04, sindy-x: 6.4780e-04, sindy-z: 1.0470e-03, sindy-reg: 6.3707\n",
      "Epoch 34800\n",
      "  train loss: 1.7073e-04, decoder: 7.4835e-05, sindy-x: 5.1344e-04, sindy-z: 4.4555e-04, sindy-reg: 6.3532\n",
      "Epoch 34900\n",
      "  train loss: 1.9410e-04, decoder: 1.1868e-04, sindy-x: 4.1854e-04, sindy-z: 3.3564e-04, sindy-reg: 6.3826\n",
      "Epoch 35000\n",
      "  train loss: 7.1302e-05, decoder: 2.0600e-05, sindy-x: 3.4434e-04, sindy-z: 1.6268e-04, sindy-reg: 6.3762\n",
      "Epoch 35100\n",
      "  train loss: 1.0006e-04, decoder: 3.3639e-05, sindy-x: 4.0273e-04, sindy-z: 2.6150e-04, sindy-reg: 6.3335\n",
      "Epoch 35200\n",
      "  train loss: 2.1640e-04, decoder: 1.1905e-04, sindy-x: 7.1329e-04, sindy-z: 2.6022e-04, sindy-reg: 6.3684\n",
      "Epoch 35300\n",
      "  train loss: 1.9417e-04, decoder: 6.0365e-05, sindy-x: 5.5781e-04, sindy-z: 7.8024e-04, sindy-reg: 6.3690\n",
      "Epoch 35400\n",
      "  train loss: 2.5760e-04, decoder: 1.6104e-04, sindy-x: 5.8619e-04, sindy-z: 3.7941e-04, sindy-reg: 6.3526\n",
      "Epoch 35500\n",
      "  train loss: 1.4104e-04, decoder: 3.2569e-05, sindy-x: 4.6042e-04, sindy-z: 6.2431e-04, sindy-reg: 6.3186\n",
      "Epoch 35600\n",
      "  train loss: 1.4654e-04, decoder: 7.1139e-05, sindy-x: 4.1218e-04, sindy-z: 3.4182e-04, sindy-reg: 6.2893\n",
      "Epoch 35700\n",
      "  train loss: 3.6883e-04, decoder: 2.5845e-04, sindy-x: 6.4659e-04, sindy-z: 4.5722e-04, sindy-reg: 6.2543\n",
      "Epoch 35800\n",
      "  train loss: 1.0895e-04, decoder: 3.0696e-05, sindy-x: 3.7645e-04, sindy-z: 4.0604e-04, sindy-reg: 6.2430\n",
      "Epoch 35900\n",
      "  train loss: 2.0449e-04, decoder: 1.2775e-04, sindy-x: 4.5861e-04, sindy-z: 3.0880e-04, sindy-reg: 6.2305\n",
      "* Evaluating\n",
      "  Time: 32.30 s, Case: [0.77 0.95], Tol: 0.00023, Max Error: 0.000582\n",
      "  Update tolerance for error indicator from 0.00023 to 0.00073\n",
      "* Update Training set: add case [0.77 0.95]\n",
      "  Max error indicator <= Tol! Current subset ratio 100.0%\n",
      "* Updating graph\n",
      "  Existing SINDys: 21, Create new SINDy: 22\n",
      "Epoch 36000\n",
      "  train loss: 6.4353e-03, decoder: 4.1423e-03, sindy-x: 8.9966e-03, sindy-z: 1.3933e-02, sindy-reg: 6.5515\n",
      "Epoch 36100\n",
      "  train loss: 1.1697e-04, decoder: 4.6114e-05, sindy-x: 4.6907e-04, sindy-z: 2.3947e-04, sindy-reg: 6.5782\n",
      "Epoch 36200\n",
      "  train loss: 2.2390e-04, decoder: 1.2852e-04, sindy-x: 6.5464e-04, sindy-z: 2.9915e-04, sindy-reg: 6.4858\n",
      "Epoch 36300\n",
      "  train loss: 2.8419e-04, decoder: 1.6690e-04, sindy-x: 6.6037e-04, sindy-z: 5.1254e-04, sindy-reg: 6.4346\n",
      "Epoch 36400\n",
      "  train loss: 1.1187e-04, decoder: 3.0656e-05, sindy-x: 3.4931e-04, sindy-z: 4.6281e-04, sindy-reg: 6.4288\n",
      "Epoch 36500\n",
      "  train loss: 1.8947e-04, decoder: 7.5205e-05, sindy-x: 4.9465e-04, sindy-z: 6.4803e-04, sindy-reg: 6.4238\n",
      "Epoch 36600\n",
      "  train loss: 1.3641e-04, decoder: 5.4972e-05, sindy-x: 4.4679e-04, sindy-z: 3.6758e-04, sindy-reg: 6.3966\n",
      "Epoch 36700\n",
      "  train loss: 1.9097e-04, decoder: 8.1098e-05, sindy-x: 4.7845e-04, sindy-z: 6.2023e-04, sindy-reg: 6.3981\n",
      "Epoch 36800\n",
      "  train loss: 1.6585e-04, decoder: 6.1446e-05, sindy-x: 4.9026e-04, sindy-z: 5.5380e-04, sindy-reg: 6.4108\n",
      "Epoch 36900\n",
      "  train loss: 9.6122e-05, decoder: 4.3521e-05, sindy-x: 2.8913e-04, sindy-z: 2.3688e-04, sindy-reg: 6.4033\n",
      "Epoch 37000\n",
      "  train loss: 1.3862e-04, decoder: 6.2826e-05, sindy-x: 3.7181e-04, sindy-z: 3.8609e-04, sindy-reg: 6.3800\n",
      "Epoch 37100\n",
      "  train loss: 1.8266e-04, decoder: 8.5894e-05, sindy-x: 4.7596e-04, sindy-z: 4.9165e-04, sindy-reg: 6.4121\n",
      "Epoch 37200\n",
      "  train loss: 1.1797e-04, decoder: 4.0723e-05, sindy-x: 3.5954e-04, sindy-z: 4.1292e-04, sindy-reg: 6.4095\n",
      "Epoch 37300\n",
      "  train loss: 1.2852e-04, decoder: 3.2913e-05, sindy-x: 3.8613e-04, sindy-z: 5.6990e-04, sindy-reg: 6.3568\n",
      "Epoch 37400\n",
      "  train loss: 1.3563e-04, decoder: 7.4082e-05, sindy-x: 3.6410e-04, sindy-z: 2.5142e-04, sindy-reg: 6.3736\n",
      "Epoch 37500\n",
      "  train loss: 2.3399e-04, decoder: 7.6855e-05, sindy-x: 4.7970e-04, sindy-z: 1.0917e-03, sindy-reg: 6.3722\n",
      "Epoch 37600\n",
      "  train loss: 2.0512e-04, decoder: 8.3091e-05, sindy-x: 4.6697e-04, sindy-z: 7.5336e-04, sindy-reg: 6.3830\n",
      "Epoch 37700\n",
      "  train loss: 1.0824e-04, decoder: 5.5422e-05, sindy-x: 3.6274e-04, sindy-z: 1.6545e-04, sindy-reg: 6.3472\n",
      "Epoch 37800\n",
      "  train loss: 1.8893e-04, decoder: 4.2511e-05, sindy-x: 4.3924e-04, sindy-z: 1.0249e-03, sindy-reg: 6.3435\n",
      "Epoch 37900\n",
      "  train loss: 3.5030e-04, decoder: 2.3286e-04, sindy-x: 5.1474e-04, sindy-z: 6.5967e-04, sindy-reg: 6.3658\n",
      "* Evaluating\n",
      "  Time: 33.63 s, Case: [0.8  0.97], Tol: 0.00073, Max Error: 0.000640\n",
      "  Update tolerance for error indicator from 0.00073 to 0.00042\n",
      "* Update Training set: add case [0.8  0.97]\n",
      "* Updating graph\n",
      "  Existing SINDys: 22, Create new SINDy: 23\n",
      "Epoch 38000\n",
      "  train loss: 4.3218e-03, decoder: 2.3598e-03, sindy-x: 4.1264e-03, sindy-z: 1.5493e-02, sindy-reg: 6.6098\n",
      "Epoch 38100\n",
      "  train loss: 2.6273e-04, decoder: 6.1395e-05, sindy-x: 4.4679e-04, sindy-z: 1.5665e-03, sindy-reg: 6.6361\n",
      "Epoch 38200\n",
      "  train loss: 3.5642e-04, decoder: 1.4346e-04, sindy-x: 5.5378e-04, sindy-z: 1.5758e-03, sindy-reg: 6.6205\n",
      "Epoch 38300\n",
      "  train loss: 4.5282e-04, decoder: 7.1678e-05, sindy-x: 1.3330e-03, sindy-z: 2.4785e-03, sindy-reg: 6.6345\n",
      "Epoch 38400\n",
      "  train loss: 2.6201e-04, decoder: 1.1096e-04, sindy-x: 4.3361e-04, sindy-z: 1.0769e-03, sindy-reg: 6.6072\n",
      "Epoch 38500\n",
      "  train loss: 4.1008e-04, decoder: 2.3330e-04, sindy-x: 6.8008e-04, sindy-z: 1.0878e-03, sindy-reg: 6.6389\n",
      "Epoch 38600\n",
      "  train loss: 3.7350e-04, decoder: 2.0160e-04, sindy-x: 7.6320e-04, sindy-z: 9.5583e-04, sindy-reg: 6.6371\n",
      "Epoch 38700\n",
      "  train loss: 1.5073e-04, decoder: 4.0859e-05, sindy-x: 4.5192e-04, sindy-z: 6.4680e-04, sindy-reg: 6.6389\n",
      "Epoch 38800\n",
      "  train loss: 4.5110e-04, decoder: 2.0760e-04, sindy-x: 7.7474e-04, sindy-z: 1.6602e-03, sindy-reg: 6.6388\n",
      "Epoch 38900\n",
      "  train loss: 1.8521e-04, decoder: 6.0040e-05, sindy-x: 5.2282e-04, sindy-z: 7.2890e-04, sindy-reg: 6.6313\n",
      "Epoch 39000\n",
      "  train loss: 1.6015e-04, decoder: 4.7099e-05, sindy-x: 4.2864e-04, sindy-z: 7.0183e-04, sindy-reg: 6.6283\n",
      "Epoch 39100\n",
      "  train loss: 1.2085e-04, decoder: 3.8298e-05, sindy-x: 3.8252e-04, sindy-z: 4.4298e-04, sindy-reg: 6.6286\n",
      "Epoch 39200\n",
      "  train loss: 2.4009e-04, decoder: 9.8161e-05, sindy-x: 8.9720e-04, sindy-z: 5.2213e-04, sindy-reg: 6.6508\n",
      "Epoch 39300\n",
      "  train loss: 2.7776e-04, decoder: 1.5466e-04, sindy-x: 3.9129e-04, sindy-z: 8.3968e-04, sindy-reg: 6.6741\n",
      "Epoch 39400\n",
      "  train loss: 3.3881e-04, decoder: 1.9898e-04, sindy-x: 5.8149e-04, sindy-z: 8.1680e-04, sindy-reg: 6.6511\n",
      "Epoch 39500\n",
      "  train loss: 3.5235e-04, decoder: 2.1304e-04, sindy-x: 6.2499e-04, sindy-z: 7.6810e-04, sindy-reg: 6.6669\n",
      "Epoch 39600\n",
      "  train loss: 1.3800e-04, decoder: 6.5220e-05, sindy-x: 4.4780e-04, sindy-z: 2.7997e-04, sindy-reg: 6.6534\n",
      "Epoch 39700\n",
      "  train loss: 1.3928e-04, decoder: 4.8015e-05, sindy-x: 3.9723e-04, sindy-z: 5.1542e-04, sindy-reg: 6.6342\n",
      "Epoch 39800\n",
      "  train loss: 2.8499e-04, decoder: 1.4226e-04, sindy-x: 5.3426e-04, sindy-z: 8.9311e-04, sindy-reg: 6.6259\n",
      "Epoch 39900\n",
      "  train loss: 1.8262e-04, decoder: 1.0136e-04, sindy-x: 4.7780e-04, sindy-z: 3.3479e-04, sindy-reg: 6.6524\n",
      "* Evaluating\n",
      "  Time: 31.38 s, Case: [0.74 1.1 ], Tol: 0.00042, Max Error: 0.000678\n",
      "  Update tolerance for error indicator from 0.00042 to 0.00066\n",
      "* Update Training set: add case [0.74 1.1 ]\n",
      "* Updating graph\n",
      "  Existing SINDys: 23, Create new SINDy: 24\n",
      "Epoch 40000\n",
      "  train loss: 1.4131e-02, decoder: 9.9541e-03, sindy-x: 2.8023e-02, sindy-z: 1.3742e-02, sindy-reg: 6.8130\n",
      "Epoch 40100\n",
      "  train loss: 1.6928e-04, decoder: 5.8822e-05, sindy-x: 3.8888e-04, sindy-z: 7.1574e-04, sindy-reg: 6.8648\n",
      "Epoch 40200\n",
      "  train loss: 3.1263e-04, decoder: 1.8093e-04, sindy-x: 9.9320e-04, sindy-z: 3.2382e-04, sindy-reg: 6.8426\n",
      "Epoch 40300\n",
      "  train loss: 2.8266e-04, decoder: 1.8566e-04, sindy-x: 5.9967e-04, sindy-z: 3.7041e-04, sindy-reg: 6.8706\n",
      "Epoch 40400\n",
      "  train loss: 1.3451e-04, decoder: 4.2967e-05, sindy-x: 3.9271e-04, sindy-z: 5.2273e-04, sindy-reg: 6.8563\n",
      "Epoch 40500\n",
      "  train loss: 5.3813e-04, decoder: 3.6406e-04, sindy-x: 9.2148e-04, sindy-z: 8.1921e-04, sindy-reg: 6.8925\n",
      "Epoch 40600\n",
      "  train loss: 1.0655e-03, decoder: 6.3178e-04, sindy-x: 9.4427e-04, sindy-z: 3.3934e-03, sindy-reg: 6.8683\n",
      "Epoch 40700\n",
      "  train loss: 4.2689e-04, decoder: 2.4887e-04, sindy-x: 6.7333e-04, sindy-z: 1.1069e-03, sindy-reg: 6.8930\n",
      "Epoch 40800\n",
      "  train loss: 4.1947e-04, decoder: 2.2261e-04, sindy-x: 7.4336e-04, sindy-z: 1.2253e-03, sindy-reg: 6.8899\n",
      "Epoch 40900\n",
      "  train loss: 2.6186e-04, decoder: 1.2082e-04, sindy-x: 7.5376e-04, sindy-z: 6.5661e-04, sindy-reg: 6.8752\n",
      "Epoch 41000\n",
      "  train loss: 6.0805e-05, decoder: 1.8214e-05, sindy-x: 2.8810e-04, sindy-z: 1.3780e-04, sindy-reg: 6.8424\n",
      "Epoch 41100\n",
      "  train loss: 2.0770e-04, decoder: 9.7841e-05, sindy-x: 5.4033e-04, sindy-z: 5.5827e-04, sindy-reg: 6.8059\n",
      "Epoch 41200\n",
      "  train loss: 3.4260e-04, decoder: 1.4016e-04, sindy-x: 8.3791e-04, sindy-z: 1.1864e-03, sindy-reg: 6.8299\n",
      "Epoch 41300\n",
      "  train loss: 2.2690e-04, decoder: 1.0255e-04, sindy-x: 8.0964e-04, sindy-z: 4.3386e-04, sindy-reg: 6.8128\n",
      "Epoch 41400\n",
      "  train loss: 3.6204e-04, decoder: 2.3318e-04, sindy-x: 4.8338e-04, sindy-z: 8.0524e-04, sindy-reg: 6.8014\n",
      "Epoch 41500\n",
      "  train loss: 1.6512e-04, decoder: 4.4792e-05, sindy-x: 3.7622e-04, sindy-z: 8.2702e-04, sindy-reg: 6.7968\n",
      "Epoch 41600\n",
      "  train loss: 4.9487e-04, decoder: 2.3749e-04, sindy-x: 1.7139e-03, sindy-z: 8.5984e-04, sindy-reg: 6.7842\n",
      "Epoch 41700\n",
      "  train loss: 9.2539e-05, decoder: 3.3001e-05, sindy-x: 3.3586e-04, sindy-z: 2.5952e-04, sindy-reg: 6.7585\n",
      "Epoch 41800\n",
      "  train loss: 7.3983e-05, decoder: 2.6691e-05, sindy-x: 2.9780e-04, sindy-z: 1.7513e-04, sindy-reg: 6.7384\n",
      "Epoch 41900\n",
      "  train loss: 1.7049e-04, decoder: 1.0965e-04, sindy-x: 3.8435e-04, sindy-z: 2.2403e-04, sindy-reg: 6.7564\n",
      "* Evaluating\n",
      "  Time: 31.39 s, Case: [0.81 0.93], Tol: 0.00066, Max Error: 0.000673\n",
      "  Update tolerance for error indicator from 0.00066 to 0.00051\n",
      "* Update Training set: add case [0.81 0.93]\n",
      "* Updating graph\n",
      "  Existing SINDys: 24, Create new SINDy: 25\n",
      "Epoch 42000\n",
      "  train loss: 1.0565e-02, decoder: 6.7091e-03, sindy-x: 1.4004e-02, sindy-z: 2.4551e-02, sindy-reg: 7.0301\n",
      "Epoch 42100\n",
      "  train loss: 3.5299e-04, decoder: 1.6180e-04, sindy-x: 8.1927e-04, sindy-z: 1.0926e-03, sindy-reg: 7.0709\n",
      "Epoch 42200\n",
      "  train loss: 2.7537e-04, decoder: 6.7955e-05, sindy-x: 7.9265e-04, sindy-z: 1.2815e-03, sindy-reg: 7.0372\n",
      "Epoch 42300\n",
      "  train loss: 2.5269e-04, decoder: 8.1578e-05, sindy-x: 8.3340e-04, sindy-z: 8.7776e-04, sindy-reg: 7.0157\n",
      "Epoch 42400\n",
      "  train loss: 1.1112e-04, decoder: 3.5885e-05, sindy-x: 3.2223e-04, sindy-z: 4.3009e-04, sindy-reg: 6.9993\n",
      "Epoch 42500\n",
      "  train loss: 2.8567e-04, decoder: 1.9310e-04, sindy-x: 5.1117e-04, sindy-z: 4.1445e-04, sindy-reg: 6.9921\n",
      "Epoch 42600\n",
      "  train loss: 2.7862e-04, decoder: 1.5936e-04, sindy-x: 5.9726e-04, sindy-z: 5.9529e-04, sindy-reg: 6.9962\n",
      "Epoch 42700\n",
      "  train loss: 8.8378e-05, decoder: 2.6372e-05, sindy-x: 3.1856e-04, sindy-z: 3.0150e-04, sindy-reg: 6.9973\n",
      "Epoch 42800\n",
      "  train loss: 1.3563e-04, decoder: 2.9894e-05, sindy-x: 3.5638e-04, sindy-z: 7.0095e-04, sindy-reg: 6.9933\n",
      "Epoch 42900\n",
      "  train loss: 2.3810e-04, decoder: 1.1273e-04, sindy-x: 7.4497e-04, sindy-z: 5.0878e-04, sindy-reg: 6.9897\n",
      "Epoch 43000\n",
      "  train loss: 2.9788e-04, decoder: 1.8386e-04, sindy-x: 6.1404e-04, sindy-z: 5.2623e-04, sindy-reg: 6.9669\n",
      "Epoch 43100\n",
      "  train loss: 2.0822e-04, decoder: 1.0880e-04, sindy-x: 5.4114e-04, sindy-z: 4.5307e-04, sindy-reg: 6.9681\n",
      "Epoch 43200\n",
      "  train loss: 3.7292e-04, decoder: 2.0297e-04, sindy-x: 1.2203e-03, sindy-z: 4.7916e-04, sindy-reg: 6.9504\n",
      "Epoch 43300\n",
      "  train loss: 2.6010e-04, decoder: 1.5525e-04, sindy-x: 7.5084e-04, sindy-z: 2.9761e-04, sindy-reg: 6.9460\n",
      "Epoch 43400\n",
      "  train loss: 1.5338e-04, decoder: 7.4741e-05, sindy-x: 6.1889e-04, sindy-z: 1.6754e-04, sindy-reg: 6.9410\n",
      "Epoch 43500\n",
      "  train loss: 1.2065e-04, decoder: 4.2577e-05, sindy-x: 4.5322e-04, sindy-z: 3.2754e-04, sindy-reg: 6.9600\n",
      "Epoch 43600\n",
      "  train loss: 1.1369e-04, decoder: 5.9076e-05, sindy-x: 3.7547e-04, sindy-z: 1.7067e-04, sindy-reg: 6.9158\n",
      "Epoch 43700\n",
      "  train loss: 1.5500e-04, decoder: 6.2459e-05, sindy-x: 4.1957e-04, sindy-z: 5.0586e-04, sindy-reg: 6.9224\n",
      "Epoch 43800\n",
      "  train loss: 1.8254e-04, decoder: 5.5128e-05, sindy-x: 4.0210e-04, sindy-z: 8.7202e-04, sindy-reg: 6.9204\n",
      "Epoch 43900\n",
      "  train loss: 1.3523e-04, decoder: 6.7744e-05, sindy-x: 3.6543e-04, sindy-z: 3.0941e-04, sindy-reg: 6.9231\n",
      "* Evaluating\n",
      "  Time: 32.55 s, Case: [0.87 1.08], Tol: 0.00051, Max Error: 0.000691\n",
      "  Update tolerance for error indicator from 0.00051 to 0.00104\n",
      "* Update Training set: add case [0.87 1.08]\n",
      "  Max error indicator <= Tol! Current subset ratio 100.0%\n",
      "  Max # SINDys 25 is reached! Training done!\n",
      "training time: 537.27 mins\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "timer = []\n",
    "timer.append(time())\n",
    "\n",
    "if not params['retrain']:\n",
    "    params['save_name'] = 'burger_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "tf.reset_default_graph()\n",
    "results_dict = train_network(train_data, params)\n",
    "df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "    \n",
    "timer.append(time())\n",
    "print(f'training time: {(timer[-1]-timer[0])/60:.2f} mins')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfvenv",
   "language": "python",
   "name": "tfvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
